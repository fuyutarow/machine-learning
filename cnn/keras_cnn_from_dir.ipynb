{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'imagenet_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-0da4b59b7ada>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_utils\u001b[0m  \u001b[0;32mimport\u001b[0m \u001b[0mget_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimagenet_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'imagenet_utils'"
     ]
    }
   ],
   "source": [
    "from keras.utils.data_utils  import get_file\n",
    "from keras import backend as K\n",
    "from keras import imagenet_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, Lambda\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "\n",
    "nb_classes = 10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Merge\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 3\n",
    "\n",
    "teacher = Sequential()\n",
    "teacher.add(Dense(10, input_shape=(784,)))\n",
    "teacher.add(Dense(10))\n",
    "teacher.add(Activation('softmax'))\n",
    "\n",
    "teacher.summary()\n",
    "teacher.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = teacher.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                    verbose=1, validation_data=(X_test, Y_test))\n",
    "score = teacher.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "for i in range(len(teacher.layers)):\n",
    "    setattr(teacher.layers[i], 'trainable', False)\n",
    "\n",
    "\n",
    "\n",
    "Y_train = np.zeros((60000, 10))\n",
    "\n",
    "\n",
    "### build student model\n",
    "student = Sequential()\n",
    "student.add(Convolution2D(32, 3, 3, input_shape=(128, 128, 3)))\n",
    "student.add(Activation('relu'))\n",
    "student.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "student.add(Convolution2D(64, 3, 3))\n",
    "student.add(Activation('relu'))\n",
    "student.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "student.add(Flatten())\n",
    "student.add(Dense(64))\n",
    "student.add(Activation('relu'))\n",
    "student.add(Dropout(0.5))\n",
    "student.add(Dense(2))\n",
    "student.add(Activation('softmax'))\n",
    "\n",
    "student.summary()\n",
    "\n",
    "student.compile(loss='categorical_crossentropy',\n",
    "               optimizer='adam',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "\n",
    "### teacher educat student\n",
    "from keras.layers import Activation, Dence, Add\n",
    "negativeActivation = lambda x: -x\n",
    "\n",
    "negativeRight = Activation(negativeActivation)(student.output) \n",
    "diff = Add()([teacher.output,negativeRight])\n",
    "\n",
    "\n",
    "model = Model(inputs=[teacher.input, student.input], outputs=[diff])\n",
    "model.compile(loss='mean_squared_error', optimizer='Adam', metrics=['acc'])\n",
    "\n",
    "model.summary(line_length=150)\n",
    "model.fit([X_train, X_train], [Y_train], batch_size=128, nb_epoch=5)\n",
    "\n",
    "\n",
    "print(student.evaluate(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EducateGenerator(object):\n",
    "    def __init__(self, train_generator, validation_generator):\n",
    "        self.train_generator = train_generator\n",
    "        self.validation_generator = validation_generator\n",
    "    def __next__(self):\n",
    "        train_batch = self.train_generator.next()\n",
    "        validation_batch = self.validation_generator.next()\n",
    "        return ([train_batch,train_batch],validation_batch)\n",
    "    def next(self):\n",
    "        train_batch = self.train_generator.next()\n",
    "        validation_batch = self.validation_generator.next()\n",
    "        return ([train_batch,train_batch],validation_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "educate_generator = EducateGenerator(\n",
    "    train_generator, validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-3b75b4f0cf79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meducate_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "educate_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 514 images belonging to 2 classes.\n",
      "Found 56 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../data/eyes/'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir + 'train',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    data_dir + 'validation',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                3686464   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 3,705,986\n",
      "Trainable params: 3,705,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fukuda/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(128, 128,...)`\n",
      "  if sys.path[0] == '':\n",
      "/home/fukuda/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 1\n",
    "\n",
    "\n",
    "student = Sequential()\n",
    "student.add(Convolution2D(32, 3, 3, input_shape=(128, 128, 3)))\n",
    "student.add(Activation('relu'))\n",
    "student.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "student.add(Convolution2D(64, 3, 3))\n",
    "student.add(Activation('relu'))\n",
    "student.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "student.add(Flatten())\n",
    "student.add(Dense(64))\n",
    "student.add(Activation('relu'))\n",
    "student.add(Dropout(0.5))\n",
    "student.add(Dense(2))\n",
    "student.add(Activation('softmax'))\n",
    "\n",
    "student.summary()\n",
    "\n",
    "student.compile(loss='categorical_crossentropy',\n",
    "               optimizer='adam',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 514 images belonging to 2 classes.\n",
      "Found 56 images belonging to 2 classes.\n",
      "2 labels {'AB': 0, 'N': 1}\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, None, None, 3) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)            (None, None, None, 32 864         input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormalizat (None, None, None, 32 128         block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)    (None, None, None, 32 0           block1_conv1_bn[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)            (None, None, None, 64 18432       block1_conv1_act[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormalizat (None, None, None, 64 256         block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)    (None, None, None, 64 0           block1_conv2_bn[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2D (None, None, None, 12 8768        block1_conv2_act[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormali (None, None, None, 12 512         block2_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation) (None, None, None, 12 0           block2_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2D (None, None, None, 12 17536       block2_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormali (None, None, None, 12 512         block2_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, None, None, 12 8192        block1_conv2_act[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, None, None, 12 0           block2_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, None, None, 12 512         conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_18 (Add)                     (None, None, None, 12 0           block2_pool[0][0]                \n",
      "                                                                   batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation) (None, None, None, 12 0           add_18[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2D (None, None, None, 25 33920       block3_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormali (None, None, None, 25 1024        block3_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation) (None, None, None, 25 0           block3_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2D (None, None, None, 25 67840       block3_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormali (None, None, None, 25 1024        block3_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, None, None, 25 32768       add_18[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, None, None, 25 0           block3_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, None, None, 25 1024        conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_19 (Add)                     (None, None, None, 25 0           block3_pool[0][0]                \n",
      "                                                                   batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation) (None, None, None, 25 0           add_19[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2D (None, None, None, 72 188672      block4_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormali (None, None, None, 72 2912        block4_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation) (None, None, None, 72 0           block4_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2D (None, None, None, 72 536536      block4_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormali (None, None, None, 72 2912        block4_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, None, None, 72 186368      add_19[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, None, None, 72 0           block4_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, None, None, 72 2912        conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_20 (Add)                     (None, None, None, 72 0           block4_pool[0][0]                \n",
      "                                                                   batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation) (None, None, None, 72 0           add_20[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2D (None, None, None, 72 536536      block5_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormali (None, None, None, 72 2912        block5_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation) (None, None, None, 72 0           block5_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2D (None, None, None, 72 536536      block5_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormali (None, None, None, 72 2912        block5_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation) (None, None, None, 72 0           block5_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2D (None, None, None, 72 536536      block5_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormali (None, None, None, 72 2912        block5_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_21 (Add)                     (None, None, None, 72 0           block5_sepconv3_bn[0][0]         \n",
      "                                                                   add_20[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation) (None, None, None, 72 0           add_21[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2D (None, None, None, 72 536536      block6_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormali (None, None, None, 72 2912        block6_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation) (None, None, None, 72 0           block6_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2D (None, None, None, 72 536536      block6_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormali (None, None, None, 72 2912        block6_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation) (None, None, None, 72 0           block6_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2D (None, None, None, 72 536536      block6_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormali (None, None, None, 72 2912        block6_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_22 (Add)                     (None, None, None, 72 0           block6_sepconv3_bn[0][0]         \n",
      "                                                                   add_21[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation) (None, None, None, 72 0           add_22[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2D (None, None, None, 72 536536      block7_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormali (None, None, None, 72 2912        block7_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation) (None, None, None, 72 0           block7_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2D (None, None, None, 72 536536      block7_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormali (None, None, None, 72 2912        block7_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation) (None, None, None, 72 0           block7_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2D (None, None, None, 72 536536      block7_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormali (None, None, None, 72 2912        block7_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_23 (Add)                     (None, None, None, 72 0           block7_sepconv3_bn[0][0]         \n",
      "                                                                   add_22[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation) (None, None, None, 72 0           add_23[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2D (None, None, None, 72 536536      block8_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormali (None, None, None, 72 2912        block8_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation) (None, None, None, 72 0           block8_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2D (None, None, None, 72 536536      block8_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormali (None, None, None, 72 2912        block8_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation) (None, None, None, 72 0           block8_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2D (None, None, None, 72 536536      block8_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormali (None, None, None, 72 2912        block8_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_24 (Add)                     (None, None, None, 72 0           block8_sepconv3_bn[0][0]         \n",
      "                                                                   add_23[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation) (None, None, None, 72 0           add_24[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2D (None, None, None, 72 536536      block9_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormali (None, None, None, 72 2912        block9_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation) (None, None, None, 72 0           block9_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2D (None, None, None, 72 536536      block9_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormali (None, None, None, 72 2912        block9_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation) (None, None, None, 72 0           block9_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2D (None, None, None, 72 536536      block9_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormali (None, None, None, 72 2912        block9_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_25 (Add)                     (None, None, None, 72 0           block9_sepconv3_bn[0][0]         \n",
      "                                                                   add_24[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activation (None, None, None, 72 0           add_25[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv2 (None, None, None, 72 536536      block10_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNormal (None, None, None, 72 2912        block10_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activation (None, None, None, 72 0           block10_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv2 (None, None, None, 72 536536      block10_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNormal (None, None, None, 72 2912        block10_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activation (None, None, None, 72 0           block10_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv2 (None, None, None, 72 536536      block10_sepconv3_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNormal (None, None, None, 72 2912        block10_sepconv3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_26 (Add)                     (None, None, None, 72 0           block10_sepconv3_bn[0][0]        \n",
      "                                                                   add_25[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activation (None, None, None, 72 0           add_26[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv2 (None, None, None, 72 536536      block11_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNormal (None, None, None, 72 2912        block11_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activation (None, None, None, 72 0           block11_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv2 (None, None, None, 72 536536      block11_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNormal (None, None, None, 72 2912        block11_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activation (None, None, None, 72 0           block11_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv2 (None, None, None, 72 536536      block11_sepconv3_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNormal (None, None, None, 72 2912        block11_sepconv3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_27 (Add)                     (None, None, None, 72 0           block11_sepconv3_bn[0][0]        \n",
      "                                                                   add_26[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activation (None, None, None, 72 0           add_27[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv2 (None, None, None, 72 536536      block12_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNormal (None, None, None, 72 2912        block12_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activation (None, None, None, 72 0           block12_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv2 (None, None, None, 72 536536      block12_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNormal (None, None, None, 72 2912        block12_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activation (None, None, None, 72 0           block12_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv2 (None, None, None, 72 536536      block12_sepconv3_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNormal (None, None, None, 72 2912        block12_sepconv3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_28 (Add)                     (None, None, None, 72 0           block12_sepconv3_bn[0][0]        \n",
      "                                                                   add_27[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activation (None, None, None, 72 0           add_28[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv2 (None, None, None, 72 536536      block13_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNormal (None, None, None, 72 2912        block13_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activation (None, None, None, 72 0           block13_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv2 (None, None, None, 10 752024      block13_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNormal (None, None, None, 10 4096        block13_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, None, None, 10 745472      add_28[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)      (None, None, None, 10 0           block13_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, None, None, 10 4096        conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_29 (Add)                     (None, None, None, 10 0           block13_pool[0][0]               \n",
      "                                                                   batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv2 (None, None, None, 15 1582080     add_29[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNormal (None, None, None, 15 6144        block14_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activation (None, None, None, 15 0           block14_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv2 (None, None, None, 20 3159552     block14_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNormal (None, None, None, 20 8192        block14_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activation (None, None, None, 20 0           block14_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2D (None, 2048)          0           block14_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "predictions (Dense)              (None, 2)             4098        avg_pool[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 20,865,578\n",
      "Trainable params: 20,811,050\n",
      "Non-trainable params: 54,528\n",
      "____________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                3686464   \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 3,705,986\n",
      "Trainable params: 3,705,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fukuda/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:54: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(128, 128,...)`\n",
      "/home/fukuda/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:58: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from xception import Xception\n",
    "\n",
    "batch_size = 32\n",
    "epoch = 10\n",
    "rescale = 128\n",
    "part ='eyes'\n",
    "\n",
    "### setup dataset\n",
    "data_dir = '../data/' +part\n",
    "target_size = (rescale, rescale)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir + '/train',\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    data_dir + '/validation',\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "\n",
    "### build teacher model\n",
    "n_labels = train_generator.num_class\n",
    "print('{} labels'.format(n_labels), train_generator.class_indices)\n",
    "\n",
    "teacher = Xception(\n",
    "    weights=None,\n",
    "    classes=n_labels)\n",
    "teacher.load_weights(\n",
    "    'models/xception.rescale=128.eyes.weghit.h5')\n",
    "teacher.summary()\n",
    "teacher.compile(loss='categorical_crossentropy',\n",
    "               optimizer='adam',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "\n",
    "### build student model\n",
    "student = Sequential()\n",
    "student.add(Convolution2D(32, 3, 3, input_shape=(128, 128, 3)))\n",
    "student.add(Activation('relu'))\n",
    "student.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "student.add(Convolution2D(64, 3, 3))\n",
    "student.add(Activation('relu'))\n",
    "student.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "student.add(Flatten())\n",
    "student.add(Dense(64))\n",
    "student.add(Activation('relu'))\n",
    "student.add(Dropout(0.5))\n",
    "student.add(Dense(2))\n",
    "student.add(Activation('softmax'))\n",
    "\n",
    "student.summary()\n",
    "\n",
    "student.compile(loss='categorical_crossentropy',\n",
    "               optimizer='adam',\n",
    "               metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                     Output Shape                     Param #           Connected to                                      \n",
      "======================================================================================================================================================\n",
      "input_2 (InputLayer)                             (None, None, None, 3)            0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)                            (None, None, None, 32)           864               input_2[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormalization)             (None, None, None, 32)           128               block1_conv1[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)                    (None, None, None, 32)           0                 block1_conv1_bn[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)                            (None, None, None, 64)           18432             block1_conv1_act[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormalization)             (None, None, None, 64)           256               block1_conv2[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)                    (None, None, None, 64)           0                 block1_conv2_bn[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2D)                (None, None, None, 128)          8768              block1_conv2_act[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormalization)          (None, None, None, 128)          512               block2_sepconv1[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation)                 (None, None, None, 128)          0                 block2_sepconv1_bn[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2D)                (None, None, None, 128)          17536             block2_sepconv2_act[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormalization)          (None, None, None, 128)          512               block2_sepconv2[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                                (None, None, None, 128)          8192              block1_conv2_act[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)                       (None, None, None, 128)          0                 block2_sepconv2_bn[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNormalization)       (None, None, None, 128)          512               conv2d_9[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "add_18 (Add)                                     (None, None, None, 128)          0                 block2_pool[0][0]                                 \n",
      "                                                                                                    batch_normalization_5[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation)                 (None, None, None, 128)          0                 add_18[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2D)                (None, None, None, 256)          33920             block3_sepconv1_act[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormalization)          (None, None, None, 256)          1024              block3_sepconv1[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation)                 (None, None, None, 256)          0                 block3_sepconv1_bn[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2D)                (None, None, None, 256)          67840             block3_sepconv2_act[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormalization)          (None, None, None, 256)          1024              block3_sepconv2[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)                               (None, None, None, 256)          32768             add_18[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)                       (None, None, None, 256)          0                 block3_sepconv2_bn[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNormalization)       (None, None, None, 256)          1024              conv2d_10[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "add_19 (Add)                                     (None, None, None, 256)          0                 block3_pool[0][0]                                 \n",
      "                                                                                                    batch_normalization_6[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation)                 (None, None, None, 256)          0                 add_19[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2D)                (None, None, None, 728)          188672            block4_sepconv1_act[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormalization)          (None, None, None, 728)          2912              block4_sepconv1[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation)                 (None, None, None, 728)          0                 block4_sepconv1_bn[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2D)                (None, None, None, 728)          536536            block4_sepconv2_act[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormalization)          (None, None, None, 728)          2912              block4_sepconv2[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)                               (None, None, None, 728)          186368            add_19[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)                       (None, None, None, 728)          0                 block4_sepconv2_bn[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNormalization)       (None, None, None, 728)          2912              conv2d_11[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "add_20 (Add)                                     (None, None, None, 728)          0                 block4_pool[0][0]                                 \n",
      "                                                                                                    batch_normalization_7[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation)                 (None, None, None, 728)          0                 add_20[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2D)                (None, None, None, 728)          536536            block5_sepconv1_act[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormalization)          (None, None, None, 728)          2912              block5_sepconv1[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation)                 (None, None, None, 728)          0                 block5_sepconv1_bn[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2D)                (None, None, None, 728)          536536            block5_sepconv2_act[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormalization)          (None, None, None, 728)          2912              block5_sepconv2[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation)                 (None, None, None, 728)          0                 block5_sepconv2_bn[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2D)                (None, None, None, 728)          536536            block5_sepconv3_act[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormalization)          (None, None, None, 728)          2912              block5_sepconv3[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "add_21 (Add)                                     (None, None, None, 728)          0                 block5_sepconv3_bn[0][0]                          \n",
      "                                                                                                    add_20[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation)                 (None, None, None, 728)          0                 add_21[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2D)                (None, None, None, 728)          536536            block6_sepconv1_act[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormalization)          (None, None, None, 728)          2912              block6_sepconv1[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation)                 (None, None, None, 728)          0                 block6_sepconv1_bn[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2D)                (None, None, None, 728)          536536            block6_sepconv2_act[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormalization)          (None, None, None, 728)          2912              block6_sepconv2[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation)                 (None, None, None, 728)          0                 block6_sepconv2_bn[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2D)                (None, None, None, 728)          536536            block6_sepconv3_act[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormalization)          (None, None, None, 728)          2912              block6_sepconv3[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "add_22 (Add)                                     (None, None, None, 728)          0                 block6_sepconv3_bn[0][0]                          \n",
      "                                                                                                    add_21[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation)                 (None, None, None, 728)          0                 add_22[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2D)                (None, None, None, 728)          536536            block7_sepconv1_act[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormalization)          (None, None, None, 728)          2912              block7_sepconv1[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation)                 (None, None, None, 728)          0                 block7_sepconv1_bn[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2D)                (None, None, None, 728)          536536            block7_sepconv2_act[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormalization)          (None, None, None, 728)          2912              block7_sepconv2[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation)                 (None, None, None, 728)          0                 block7_sepconv2_bn[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2D)                (None, None, None, 728)          536536            block7_sepconv3_act[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormalization)          (None, None, None, 728)          2912              block7_sepconv3[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "add_23 (Add)                                     (None, None, None, 728)          0                 block7_sepconv3_bn[0][0]                          \n",
      "                                                                                                    add_22[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation)                 (None, None, None, 728)          0                 add_23[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2D)                (None, None, None, 728)          536536            block8_sepconv1_act[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormalization)          (None, None, None, 728)          2912              block8_sepconv1[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation)                 (None, None, None, 728)          0                 block8_sepconv1_bn[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2D)                (None, None, None, 728)          536536            block8_sepconv2_act[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormalization)          (None, None, None, 728)          2912              block8_sepconv2[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation)                 (None, None, None, 728)          0                 block8_sepconv2_bn[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2D)                (None, None, None, 728)          536536            block8_sepconv3_act[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormalization)          (None, None, None, 728)          2912              block8_sepconv3[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "add_24 (Add)                                     (None, None, None, 728)          0                 block8_sepconv3_bn[0][0]                          \n",
      "                                                                                                    add_23[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation)                 (None, None, None, 728)          0                 add_24[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2D)                (None, None, None, 728)          536536            block9_sepconv1_act[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormalization)          (None, None, None, 728)          2912              block9_sepconv1[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation)                 (None, None, None, 728)          0                 block9_sepconv1_bn[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2D)                (None, None, None, 728)          536536            block9_sepconv2_act[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormalization)          (None, None, None, 728)          2912              block9_sepconv2[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation)                 (None, None, None, 728)          0                 block9_sepconv2_bn[0][0]                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2D)                (None, None, None, 728)          536536            block9_sepconv3_act[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormalization)          (None, None, None, 728)          2912              block9_sepconv3[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "add_25 (Add)                                     (None, None, None, 728)          0                 block9_sepconv3_bn[0][0]                          \n",
      "                                                                                                    add_24[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activation)                (None, None, None, 728)          0                 add_25[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv2D)               (None, None, None, 728)          536536            block10_sepconv1_act[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNormalization)         (None, None, None, 728)          2912              block10_sepconv1[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activation)                (None, None, None, 728)          0                 block10_sepconv1_bn[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv2D)               (None, None, None, 728)          536536            block10_sepconv2_act[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNormalization)         (None, None, None, 728)          2912              block10_sepconv2[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activation)                (None, None, None, 728)          0                 block10_sepconv2_bn[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv2D)               (None, None, None, 728)          536536            block10_sepconv3_act[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNormalization)         (None, None, None, 728)          2912              block10_sepconv3[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "add_26 (Add)                                     (None, None, None, 728)          0                 block10_sepconv3_bn[0][0]                         \n",
      "                                                                                                    add_25[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activation)                (None, None, None, 728)          0                 add_26[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv2D)               (None, None, None, 728)          536536            block11_sepconv1_act[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNormalization)         (None, None, None, 728)          2912              block11_sepconv1[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activation)                (None, None, None, 728)          0                 block11_sepconv1_bn[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv2D)               (None, None, None, 728)          536536            block11_sepconv2_act[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNormalization)         (None, None, None, 728)          2912              block11_sepconv2[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activation)                (None, None, None, 728)          0                 block11_sepconv2_bn[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv2D)               (None, None, None, 728)          536536            block11_sepconv3_act[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNormalization)         (None, None, None, 728)          2912              block11_sepconv3[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "add_27 (Add)                                     (None, None, None, 728)          0                 block11_sepconv3_bn[0][0]                         \n",
      "                                                                                                    add_26[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activation)                (None, None, None, 728)          0                 add_27[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv2D)               (None, None, None, 728)          536536            block12_sepconv1_act[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNormalization)         (None, None, None, 728)          2912              block12_sepconv1[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activation)                (None, None, None, 728)          0                 block12_sepconv1_bn[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv2D)               (None, None, None, 728)          536536            block12_sepconv2_act[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNormalization)         (None, None, None, 728)          2912              block12_sepconv2[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activation)                (None, None, None, 728)          0                 block12_sepconv2_bn[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv2D)               (None, None, None, 728)          536536            block12_sepconv3_act[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNormalization)         (None, None, None, 728)          2912              block12_sepconv3[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "add_28 (Add)                                     (None, None, None, 728)          0                 block12_sepconv3_bn[0][0]                         \n",
      "                                                                                                    add_27[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activation)                (None, None, None, 728)          0                 add_28[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv2D)               (None, None, None, 728)          536536            block13_sepconv1_act[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNormalization)         (None, None, None, 728)          2912              block13_sepconv1[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2d_13_input (InputLayer)                     (None, 128, 128, 3)              0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activation)                (None, None, None, 728)          0                 block13_sepconv1_bn[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)                               (None, 126, 126, 32)             896               conv2d_13_input[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv2D)               (None, None, None, 1024)         752024            block13_sepconv2_act[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_14 (Activation)                       (None, 126, 126, 32)             0                 conv2d_13[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNormalization)         (None, None, None, 1024)         4096              block13_sepconv2[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)                               (None, None, None, 1024)         745472            add_28[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)                   (None, 63, 63, 32)               0                 activation_14[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)                      (None, None, None, 1024)         0                 block13_sepconv2_bn[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNormalization)       (None, None, None, 1024)         4096              conv2d_12[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)                               (None, 61, 61, 64)               18496             max_pooling2d_5[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "add_29 (Add)                                     (None, None, None, 1024)         0                 block13_pool[0][0]                                \n",
      "                                                                                                    batch_normalization_8[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_15 (Activation)                       (None, 61, 61, 64)               0                 conv2d_14[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv2D)               (None, None, None, 1536)         1582080           add_29[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)                   (None, 30, 30, 64)               0                 activation_15[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNormalization)         (None, None, None, 1536)         6144              block14_sepconv1[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)                              (None, 57600)                    0                 max_pooling2d_6[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activation)                (None, None, None, 1536)         0                 block14_sepconv1_bn[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dense_5 (Dense)                                  (None, 64)                       3686464           flatten_3[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv2D)               (None, None, None, 2048)         3159552           block14_sepconv1_act[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_16 (Activation)                       (None, 64)                       0                 dense_5[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNormalization)         (None, None, None, 2048)         8192              block14_sepconv2[0][0]                            \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)                              (None, 64)                       0                 activation_16[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activation)                (None, None, None, 2048)         0                 block14_sepconv2_bn[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dense_6 (Dense)                                  (None, 2)                        130               dropout_3[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2D)                (None, 2048)                     0                 block14_sepconv2_act[0][0]                        \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_17 (Activation)                       (None, 2)                        0                 dense_6[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "predictions (Dense)                              (None, 2)                        4098              avg_pool[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_19 (Activation)                       (None, 2)                        0                 activation_17[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "add_31 (Add)                                     (None, 2)                        0                 predictions[0][0]                                 \n",
      "                                                                                                    activation_19[0][0]                               \n",
      "======================================================================================================================================================\n",
      "Total params: 24,571,564\n",
      "Trainable params: 24,517,036\n",
      "Non-trainable params: 54,528\n",
      "______________________________________________________________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  9/200 [>.............................] - ETA: 231s - loss: 0.5028 - acc: 0.6493"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-11df8d63ba9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0meducate_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#train_generator.n//batch_size,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     epochs=5)\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;31m#    validation_data=validation_generator,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#    validation_steps=20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fukuda/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fukuda/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2009\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fukuda/anaconda3/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import Activation, Dropout, Flatten, Dense, Add\n",
    "from keras.models import Model\n",
    "\n",
    "class EducateGenerator(object):\n",
    "    def __init__(self, train_generator):\n",
    "        self.train_generator = train_generator\n",
    "        self.validation_generator = validation_generator\n",
    "    def __next__(self):\n",
    "        x_train, y_train = self.train_generator.next()\n",
    "        return ( [x_train,x_train], y_train )\n",
    "    def next(self):\n",
    "        return self.__next__()\n",
    "\n",
    "# .next() -> ([x_train,x_train],y_train)\n",
    "educate_generator = EducateGenerator(\n",
    "    train_generator)\n",
    "    #, validation_generator)\n",
    "\n",
    "\n",
    "### teacher educat student\n",
    "negativeActivation = lambda x: -x\n",
    "\n",
    "negativeRight = Activation(negativeActivation)(student.output)\n",
    "diff = Add()([teacher.output,negativeRight])\n",
    "\n",
    "model = Model(inputs=[teacher.input, student.input], outputs=[diff])\n",
    "model.compile(loss='mean_squared_error', optimizer='Adam', metrics=['acc'])\n",
    "\n",
    "model.summary(line_length=150)\n",
    "#model.fit([X_train, X_train], [Y_train], batch_size=128, nb_epoch=5)\n",
    "history = model.fit_generator(\n",
    "    educate_generator,\n",
    "    steps_per_epoch=200,#train_generator.n//batch_size,\n",
    "    epochs=5)\n",
    "#    validation_data=validation_generator,\n",
    "#    validation_steps=20\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_obtain_input_shape() got an unexpected keyword argument 'include_top'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-90bea98913b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSqueezeNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../images/cat.jpeg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m227\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m227\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fukuda/anaconda3/lib/python3.6/site-packages/keras_squeezenet/squeezenet.py\u001b[0m in \u001b[0;36mSqueezeNet\u001b[0;34m(input_tensor, input_shape, weights, classes)\u001b[0m\n\u001b[1;32m     60\u001b[0m                          ' as true, `classes` should be 1000')\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     input_shape = _obtain_input_shape(input_shape,\n\u001b[1;32m     64\u001b[0m                                       \u001b[0mdefault_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m227\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _obtain_input_shape() got an unexpected keyword argument 'include_top'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras_squeezenet import SqueezeNet\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "\n",
    "model = SqueezeNet()\n",
    "\n",
    "img = image.load_img('../images/cat.jpeg', target_size=(227, 227))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "print('Predicted:', decode_predictions(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (32,128,128,3) into shape (32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-78f8d7df1360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (32,128,128,3) into shape (32)"
     ]
    }
   ],
   "source": [
    "A = train_generator.next()\n",
    "np.concatenate((A,A), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (32,128,128,3) into shape (32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-b33aa84f49da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meducate_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-77-f1dd6a786abe>\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m# .next() -> ([x_train,x_train],y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m educate_generator = EducateGenerator(\n",
      "\u001b[0;32m<ipython-input-77-f1dd6a786abe>\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtrain_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mvalidation_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (32,128,128,3) into shape (32)"
     ]
    }
   ],
   "source": [
    "educate_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fukuda/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  import sys\n",
      "/home/fukuda/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=<keras.pre..., steps_per_epoch=6, epochs=1, validation_steps=200)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "5/6 [========================>.....] - ETA: 1s - loss: 0.9498 - acc: 0.4562"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d597e9a8553e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     nb_val_samples=200)\n\u001b[0m",
      "\u001b[0;32m/home/fukuda/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fukuda/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[1;32m   1119\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fukuda/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fukuda/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2062\u001b[0m                                 \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m                                 \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2064\u001b[0;31m                                 use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   2065\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m                             \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fukuda/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fukuda/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m                     raise ValueError('Output of generator should be a tuple '\n",
      "\u001b[0;32m/home/fukuda/anaconda3/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=200,\n",
    "    nb_epoch=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-121b5d180134>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresult_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./models/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'smallcnn.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msave_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'history_smallcnn.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "result_dir = './models/'\n",
    "model.save_weights(os.path.join(result_dir, 'smallcnn.h5'))\n",
    "save_history(history, os.path.join(result_dir, 'history_smallcnn.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__next__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_flow_index',\n",
       " 'batch_index',\n",
       " 'batch_size',\n",
       " 'class_indices',\n",
       " 'class_mode',\n",
       " 'classes',\n",
       " 'color_mode',\n",
       " 'data_format',\n",
       " 'directory',\n",
       " 'filenames',\n",
       " 'image_data_generator',\n",
       " 'image_shape',\n",
       " 'index_generator',\n",
       " 'lock',\n",
       " 'n',\n",
       " 'next',\n",
       " 'num_class',\n",
       " 'reset',\n",
       " 'samples',\n",
       " 'save_format',\n",
       " 'save_prefix',\n",
       " 'save_to_dir',\n",
       " 'shuffle',\n",
       " 'target_size',\n",
       " 'total_batches_seen']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\n",
      "\n",
      "brain_dir = '../micin/brain/'\n",
      "data_dir = '../data/brain/'\n",
      "\n",
      "labels = ['N','MS','PD','PS']\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "\n",
      "\n",
      "# 'PS116.jpg' -> ['PS', '116', '.jpg']\n",
      "import itertools\n",
      "strint_separator = lambda f:\\\n",
      "    [''.join(it) for _, it in itertools.groupby(f,str.isdigit)]\n",
      "import os\n",
      "\n",
      "brain_dir = '../micin/brain/'\n",
      "data_dir = '../data/brain/'\n",
      "\n",
      "labels = ['N','MS','PD','PS']\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "\n",
      "\n",
      "# 'PS116.jpg' -> ['PS', '116', '.jpg']\n",
      "import itertools\n",
      "strint_separator = lambda f:\\\n",
      "    [''.join(it) for _, it in itertools.groupby(f,str.isdigit)]\n",
      "flist = [ f for f in os.listdir(brain_dir) if '.jpg' in f ] # for removing .DS_Store\n",
      "flist\n",
      "\n",
      "\n",
      "for fname in flist:\n",
      "    label = strint_separator(fname)[0] # 'N','MS','PD' or'PS'\n",
      "    read_fname = brain_dir + fname\n",
      "    write_fname = data_dir + label + '/' + fname\n",
      "    print(read_fname, write_fname)\n",
      "    #open(write_fname, 'wb').write(open(read_fname,'rb').read())\n",
      "import os\n",
      "\n",
      "brain_dir = '../micin/brain/'\n",
      "data_dir = '../data/brain/'\n",
      "\n",
      "labels = ['N','MS','PD','PS']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "\n",
      "\n",
      "# 'PS116.jpg' -> ['PS', '116', '.jpg']\n",
      "import itertools\n",
      "strint_separator = lambda f:\\\n",
      "    [''.join(it) for _, it in itertools.groupby(f,str.isdigit)]\n",
      "import os\n",
      "\n",
      "brain_dir = '../micin/brain/'\n",
      "data_dir = '../data/brain/'\n",
      "\n",
      "labels = ['N','MS','PD','PS']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "\n",
      "\n",
      "# 'PS116.jpg' -> ['PS', '116', '.jpg']\n",
      "import itertools\n",
      "strint_separator = lambda f:\\\n",
      "    [''.join(it) for _, it in itertools.groupby(f,str.isdigit)]\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/brain/'\n",
      "\n",
      "df = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "labels = ['N','AB']\n",
      "\n",
      "fname_labels = []\n",
      "for row in df.iterrows():\n",
      "    read_fname = eyes_dir + row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (read_fname, label)\n",
      "    print(d)\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/brain/'\n",
      "\n",
      "df = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "labels = ['N','AB']\n",
      "\n",
      "fname_labels = [] # [ (read_fname, label),(),(),,, ]\n",
      "for row in df.iterrows():\n",
      "    read_fname = eyes_dir + row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (read_fname, label)\n",
      "    fname_labels.append(d)\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "\n",
      "labels = ['N','AB']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "    \n",
      "df = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "\n",
      "fname_labels = [] # [ (read_fname, label),(),(),,, ]\n",
      "for row in df.iterrows():\n",
      "    read_fname = eyes_dir + row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (read_fname, label)\n",
      "    fname_labels.append(d)\n",
      "for read_fname, label in fname_labels:\n",
      "    write_fname = data_dir + label + '/' + fname\n",
      "    print(read_fname, write_fname)\n",
      "    #open(write_fname, 'wb').write(open(read_fname,'rb').read())\n",
      "for read_fname, label in fname_labels:\n",
      "    write_fname = data_dir + label + '/' + read_fname\n",
      "    print(read_fname, write_fname)\n",
      "    #open(write_fname, 'wb').write(open(read_fname,'rb').read())\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "\n",
      "labels = ['N','AB']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "    \n",
      "df = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "\n",
      "fname_labels = [] # [ (fname, label),(),(),,, ]\n",
      "for row in df.iterrows():\n",
      "    fname = eyes_dir + row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (read_fname, label)\n",
      "    fname_labels.append(d)\n",
      "fname_labels\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "\n",
      "labels = ['N','AB']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "    \n",
      "df = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "\n",
      "fname_labels = [] # [ (fname, label),(),(),,, ]\n",
      "for row in df.iterrows():\n",
      "    fname = row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (read_fname, label)\n",
      "    fname_labels.append(d)\n",
      "fname_labels\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "\n",
      "labels = ['N','AB']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "    \n",
      "df = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "\n",
      "fname_labels = [] # [ (fname, label),(),(),,, ]\n",
      "for row in df.iterrows():\n",
      "    fname = row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (read_fname, label)\n",
      "    fname_labels.append(d)\n",
      "fname_labels\n",
      "fname_labels\n",
      "df\n",
      "df\n",
      "df\n",
      "df\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "\n",
      "labels = ['N','AB']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "    \n",
      "df = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "\n",
      "fname_labels = [] # [ (fname, label),(),(),,, ]\n",
      "for row in df.iterrows():\n",
      "    fname = row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (fname, label)\n",
      "    fname_labels.append(d)\n",
      "fname_labels\n",
      "for fname, label in fname_labels:\n",
      "    read_fname = eyes_dir + fname\n",
      "    write_fname = data_dir + label + '/' + read_fname\n",
      "    print(read_fname, write_fname)\n",
      "    #open(write_fname, 'wb').write(open(read_fname,'rb').read())\n",
      "for fname, label in fname_labels:\n",
      "    read_fname = eyes_dir + fname\n",
      "    write_fname = data_dir + label + '/' + fname\n",
      "    print(read_fname, write_fname)\n",
      "    #open(write_fname, 'wb').write(open(read_fname,'rb').read())\n",
      "for fname, label in fname_labels:\n",
      "    read_fname = eyes_dir + fname\n",
      "    write_fname = data_dir + label + '/' + fname\n",
      "    open(write_fname, 'wb').write(open(read_fname,'rb').read())\n",
      "train_datagen = ImageDataGenerator(\n",
      "    rescale=1.0 / 255,\n",
      "    shear_range=0.2,\n",
      "    zoom_range=0.2,\n",
      "    horizontal_flip=True)\n",
      "\n",
      "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
      "\n",
      "\n",
      "train_generator = train_datagen.flow_from_directory(\n",
      "    '../data/brain/,\n",
      "    target_size=(128, 128),\n",
      "    batch_size=batch_size,\n",
      "    class_mode='categorical')\n",
      "train_datagen = ImageDataGenerator(\n",
      "    rescale=1.0 / 255,\n",
      "    shear_range=0.2,\n",
      "    zoom_range=0.2,\n",
      "    horizontal_flip=True)\n",
      "\n",
      "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
      "\n",
      "\n",
      "train_generator = train_datagen.flow_from_directory(\n",
      "    '../data/brain/',\n",
      "    target_size=(128, 128),\n",
      "    batch_size=batch_size,\n",
      "    class_mode='categorical')\n",
      "from keras.preprocessing.image import ImageDataGenerator\n",
      "\n",
      "train_datagen = ImageDataGenerator(\n",
      "    rescale=1.0 / 255,\n",
      "    shear_range=0.2,\n",
      "    zoom_range=0.2,\n",
      "    horizontal_flip=True)\n",
      "\n",
      "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
      "\n",
      "\n",
      "train_generator = train_datagen.flow_from_directory(\n",
      "    '../data/brain/',\n",
      "    target_size=(128, 128),\n",
      "    batch_size=batch_size,\n",
      "    class_mode='categorical')\n",
      "from keras.preprocessing.image import ImageDataGenerator\n",
      "\n",
      "train_datagen = ImageDataGenerator(\n",
      "    rescale=1.0 / 255,\n",
      "    shear_range=0.2,\n",
      "    zoom_range=0.2,\n",
      "    horizontal_flip=True)\n",
      "\n",
      "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
      "\n",
      "\n",
      "train_generator = train_datagen.flow_from_directory(\n",
      "    '../data/brain/',\n",
      "    target_size=(128, 128),\n",
      "    batch_size=30,\n",
      "    class_mode='categorical')\n",
      "train_generator\n",
      "dir(train_generator)\n",
      "train_generator.__next__()\n",
      "train_generator.__next__().shape\n",
      "train_generator.__next__()[0].shape\n",
      "train_generator.__next__()[1].shape\n",
      "train_generator.__next__()[1]#.shape\n",
      "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
      "y_train = np_utils.to_categorical(y_train, num_classes)\n",
      "y_test = np_utils.to_categorical(y_test, num_classes)\n",
      "from keras.datasets import cifar10\n",
      "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
      "y_train = np_utils.to_categorical(y_train, num_classes)\n",
      "y_test = np_utils.to_categorical(y_test, num_classes)\n",
      "import keras\n",
      "from keras.datasets import cifar10\n",
      "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
      "\n",
      "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
      "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
      "num_classes = 10\n",
      "import keras\n",
      "from keras.datasets import cifar10\n",
      "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
      "\n",
      "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
      "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
      "x_train.shape\n",
      "train_generator = train_datagen.fit(\n",
      "    x_train,\n",
      "    target_size=(128, 128),\n",
      "    batch_size=30,\n",
      "    class_mode='categorical')\n",
      "train_generator = train_datagen.fit(\n",
      "    x_train,\n",
      "    #target_size=(128, 128),\n",
      "    batch_size=30,\n",
      "    class_mode='categorical')\n",
      "train_generator = train_datagen.fit(\n",
      "    x_data, y_data,\n",
      "    target_size=(128, 128),\n",
      "    batch_size=30,\n",
      "    class_mode='categorical')\n",
      "train_generator = train_datagen.fit(\n",
      "    x_train, y_train,\n",
      "    target_size=(128, 128),\n",
      "    batch_size=30,\n",
      "    class_mode='categorical')\n",
      "train_generator = train_datagen.fit(\n",
      "    x_train, y_train,\n",
      "    #target_size=(128, 128),\n",
      "    batch_size=30,\n",
      "    class_mode='categorical')\n",
      "train_generator = train_datagen.flow(\n",
      "    x_train, y_train,\n",
      "    #target_size=(128, 128),\n",
      "    batch_size=30,\n",
      "    class_mode='categorical')\n",
      "train_generator = train_datagen.flow(\n",
      "    x_train, y_train,\n",
      "    #target_size=(128, 128),\n",
      "    batch_size=30,\n",
      "    #class_mode='categorical'\n",
      ")\n",
      "train_generator = train_datagen.flow(\n",
      "    x_train, y_train,\n",
      "    target_size=(128, 128),\n",
      "    batch_size=30,\n",
      "    #class_mode='categorical'\n",
      ")\n",
      "y_train\n",
      "from keras.preprocessing.image import ImageDataGenerator\n",
      "\n",
      "train_datagen = ImageDataGenerator(\n",
      "    rescale=1.0 / 255,\n",
      "    shear_range=0.2,\n",
      "    zoom_range=0.2,\n",
      "    horizontal_flip=True)\n",
      "\n",
      "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
      "\n",
      "\n",
      "train_generator = train_datagen.flow_from_directory(\n",
      "    '../data/brain/',\n",
      "    target_size=(128, 128),\n",
      "    batch_size=30,\n",
      "    class_mode='categorical')\n",
      "train_generator.__next__()\n",
      "dir(train_generator)\n",
      "train_generator.__class__\n",
      "train_generator.__class__()\n",
      "train_generator.__class__\n",
      "train_generator.calsses\n",
      "train_generator.calsses()\n",
      "train_generator.classes\n",
      "train_generator.n\n",
      "train_generator.target_size\n",
      "train_generator.sample\n",
      "train_generator.sample()\n",
      "train_generator.samples\n",
      "train_generator.n\n",
      "from keras.preprocessing.image import ImageDataGenerator\n",
      "\n",
      "train_datagen = ImageDataGenerator(\n",
      "    rescale=1.0 / 255,\n",
      "    shear_range=0.2,\n",
      "    zoom_range=0.2,\n",
      "    horizontal_flip=True)\n",
      "\n",
      "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
      "\n",
      "\n",
      "train_generator = train_datagen.flow_from_directory(\n",
      "    '../data/eyes/',\n",
      "    target_size=(128, 128),\n",
      "    batch_size=30,\n",
      "    class_mode='categorical')\n",
      "train_generator.n\n",
      "import os\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "\n",
      "labels = ['N','AB']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "\n",
      "\n",
      "df = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "\n",
      "fname_labels = [] # [ (fname, label),(),(),,, ]\n",
      "for row in df.iterrows():\n",
      "    fname = row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (fname, label)\n",
      "    fname_labels.append(d)\n",
      "\n",
      "for fname, label in fname_labels:\n",
      "    read_fname = eyes_dir + fname\n",
      "    write_fname = data_dir + label + '/' + fname\n",
      "    open(write_fname, 'wb').write(open(read_fname,'rb').read())\n",
      "import os\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "\n",
      "labels = ['N','AB']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "\n",
      "\n",
      "df = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "\n",
      "fname_labels = [] # [ (fname, label),(),(),,, ]\n",
      "for row in df.iterrows():\n",
      "    fname = row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (fname, label)\n",
      "    fname_labels.append(d)\n",
      "\n",
      "fname_labels\n",
      "pd.DataFrame(fname_labels)\n",
      "df = pd.DataFrame(fname_labels)\n",
      "import os\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "\n",
      "labels = ['N','AB']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "\n",
      "\n",
      "df_tmp = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "\n",
      "fname_labels = [] # [ (fname, label),(),(),,, ]\n",
      "for row in df_tmp.iterrows():\n",
      "    fname = row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (fname, label)\n",
      "    fname_labels.append(d)\n",
      "\n",
      "df = pd.DataFrame(fname_labels)\n",
      "df\n",
      "data = df\n",
      "\n",
      "low_frequentry_data = data[data.label == 0].index\n",
      "low_frequentry_data_sample = data.loc[low_frequentry_data]\n",
      "pd.DataFrame(low_frequentry_data_sample)\n",
      "df\n",
      "import os\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "\n",
      "labels = ['N','AB']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "\n",
      "\n",
      "df_tmp = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "\n",
      "fname_labels = [('fname', 'label')] # [ (fname, label),(),(),,, ]\n",
      "for row in df_tmp.iterrows():\n",
      "    fname = row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (fname, label)\n",
      "    fname_labels.append(d)\n",
      "\n",
      "df = pd.DataFrame(fname_labels)\n",
      "df\n",
      "import os\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "\n",
      "labels = ['N','AB']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "\n",
      "\n",
      "df_tmp = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "\n",
      "fname_labels = [] # [ (fname, label),(),(),,, ]\n",
      "for row in df_tmp.iterrows():\n",
      "    fname = row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (fname, label)\n",
      "    fname_labels.append(d)\n",
      "\n",
      "df = pd.DataFrame(fname_labels,\n",
      "                  index=['fname', 'label'])\n",
      "import os\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "\n",
      "labels = ['N','AB']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "\n",
      "\n",
      "df_tmp = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "\n",
      "fname_labels = [] # [ (fname, label),(),(),,, ]\n",
      "for row in df_tmp.iterrows():\n",
      "    fname = row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (fname, label)\n",
      "    fname_labels.append(d)\n",
      "\n",
      "df = pd.DataFrame(fname_labels,\n",
      "                  columns=['fname', 'label'])\n",
      "df\n",
      "data = df\n",
      "\n",
      "low_frequentry_data = data[data.label == 0].index\n",
      "low_frequentry_data_sample = data.loc[low_frequentry_data]\n",
      "pd.DataFrame(low_frequentry_data_sample)\n",
      "import os\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "\n",
      "labels = ['N','AB']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "\n",
      "\n",
      "df_tmp = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "\n",
      "fname_labels = [] # [ (fname, label),(),(),,, ]\n",
      "for row in df_tmp.iterrows():\n",
      "    fname = row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (fname, label)\n",
      "    fname_labels.append(d)\n",
      "\n",
      "df = pd.DataFrame(fname_labels,\n",
      "                  columns=['fname', 'label'])\n",
      "data = df\n",
      "\n",
      "low_frequentry_data = data[data.label == 0].index\n",
      "low_frequentry_data_sample = data.loc[low_frequentry_data]\n",
      "pd.DataFrame(low_frequentry_data_sample)\n",
      "import os\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "\n",
      "labels = ['N','AB']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "\n",
      "\n",
      "df_tmp = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "\n",
      "fname_labels = [] # [ (fname, label),(),(),,, ]\n",
      "for row in df_tmp.iterrows():\n",
      "    fname = row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (fname, label)\n",
      "    fname_labels.append(d)\n",
      "\n",
      "df = pd.DataFrame(fname_labels,\n",
      "                  columns=['fname', 'label'])\n",
      "df\n",
      "data = df\n",
      "\n",
      "low_frequentry_data = data[data.label == 'AB'].index\n",
      "low_frequentry_data_sample = data.loc[low_frequentry_data]\n",
      "pd.DataFrame(low_frequentry_data_sample)\n",
      "data = df\n",
      "\n",
      "low_frequentry_data = data[data.label == 'AB'].index\n",
      "low_frequentry_data\n",
      "#low_frequentry_data_sample = data.loc[low_frequentry_data]\n",
      "#pd.DataFrame(low_frequentry_data_sample)\n",
      "data = df\n",
      "\n",
      "low_frequentry_data = data[data.label == 'AB'].index\n",
      "low_frequentry_data_sample = data.loc[low_frequentry_data]\n",
      "low_frequentry_data_sample\n",
      "#pd.DataFrame(low_frequentry_data_sample)\n",
      "high_frequentry_data = data[data.label == 'N'].index\n",
      "# 出現頻度の小さいクラスに、大きいクラスの個数を合わせてランダムにデータを抽出する\n",
      "random_indices = np.random.choice(high_frequentry_data, sampling_size, replace=False)\n",
      "high_frequentry_data_sample = data.loc[random_indices]\n",
      "pd.DataFrame(high_frequentry_data_sample)\n",
      "import numpy as np\n",
      "high_frequentry_data = data[data.label == 'N'].index\n",
      "# 出現頻度の小さいクラスに、大きいクラスの個数を合わせてランダムにデータを抽出する\n",
      "random_indices = np.random.choice(high_frequentry_data, sampling_size, replace=False)\n",
      "high_frequentry_data_sample = data.loc[random_indices]\n",
      "pd.DataFrame(high_frequentry_data_sample)\n",
      "import numpy as np\n",
      "sampling_size = len(data[data.label == 0])\n",
      "high_frequentry_data = data[data.label == 'N'].index\n",
      "# 出現頻度の小さいクラスに、大きいクラスの個数を合わせてランダムにデータを抽出する\n",
      "random_indices = np.random.choice(high_frequentry_data, sampling_size, replace=False)\n",
      "high_frequentry_data_sample = data.loc[random_indices]\n",
      "pd.DataFrame(high_frequentry_data_sample)\n",
      "import os\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "\n",
      "labels = ['N','AB']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "\n",
      "\n",
      "df_tmp = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "\n",
      "fname_labels = [] # [ (fname, label),(),(),,, ]\n",
      "for row in df_tmp.iterrows():\n",
      "    fname = row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (fname, label)\n",
      "    fname_labels.append(d)\n",
      "\n",
      "df = pd.DataFrame(fname_labels,\n",
      "                  columns=['fname', 'label'])\n",
      "data = df\n",
      "\n",
      "low_frequentry_data = data[data.label == 'AB'].index\n",
      "low_frequentry_data_sample = data.loc[low_frequentry_data]\n",
      "#low_frequentry_data_sample\n",
      "pd.DataFrame(low_frequentry_data_sample)\n",
      "import numpy as np\n",
      "sampling_size = len(data[data.label == 0])\n",
      "high_frequentry_data = data[data.label == 'N'].index\n",
      "# 出現頻度の小さいクラスに、大きいクラスの個数を合わせてランダムにデータを抽出する\n",
      "random_indices = np.random.choice(high_frequentry_data, sampling_size, replace=False)\n",
      "high_frequentry_data_sample = data.loc[random_indices]\n",
      "pd.DataFrame(high_frequentry_data_sample)\n",
      "high_frequentry_data = data[data.label == 'N'].index\n",
      "high_frequentry_data\n",
      "high_frequentry_data = data[data.label == 'N'].index\n",
      "high_frequentry_data\n",
      "random_indices = np.random.choice(high_frequentry_data, sampling_size, replace=False)\n",
      "random_indices\n",
      "import numpy as np\n",
      "sampling_size = len(data[data.label == 'AB'])\n",
      "high_frequentry_data = data[data.label == 'N'].index\n",
      "high_frequentry_data\n",
      "random_indices = np.random.choice(high_frequentry_data, sampling_size, replace=False)\n",
      "random_indices\n",
      "high_frequentry_data = data[data.label == 'N'].index\n",
      "# 出現頻度の小さいクラスに、大きいクラスの個数を合わせてランダムにデータを抽出する\n",
      "random_indices = np.random.choice(high_frequentry_data, sampling_size, replace=False)\n",
      "high_frequentry_data_sample = data.loc[random_indices]\n",
      "pd.DataFrame(high_frequentry_data_sample)\n",
      "df\n",
      "df.label\n",
      "dir(df.label)\n",
      "labels\n",
      "[ len(df[df.label == label ]) for label in labels ]\n",
      "min([ len(df[df.label == label ]) for label in labels ])\n",
      "n_min_class_data = min([ len(df[df.label == label ]) for label in labels ])\n",
      "high_frequentry_data = data[data.label == 'N'].index\n",
      "\n",
      "for label in lables:\n",
      "    class_data = df[df.label == label ]\n",
      "    # 出現頻度の小さいクラスに、大きいクラスの個数を合わせてランダムにデータを抽出する\n",
      "    idx = np.random.choice( class_data, sampling_size, replace=False)\n",
      "    downsize_class_data = data.loc[idx]\n",
      "    pd.DataFrame(downsize_class_data)\n",
      "high_frequentry_data = data[data.label == 'N'].index\n",
      "\n",
      "for label in labels:\n",
      "    class_data = df[df.label == label ]\n",
      "    # 出現頻度の小さいクラスに、大きいクラスの個数を合わせてランダムにデータを抽出する\n",
      "    idx = np.random.choice( class_data, sampling_size, replace=False)\n",
      "    downsize_class_data = data.loc[idx]\n",
      "    pd.DataFrame(downsize_class_data)\n",
      "high_frequentry_data = data[data.label == 'N'].index\n",
      "\n",
      "for label in labels:\n",
      "    class_data = df[ df.label == label ].index\n",
      "    # 出現頻度の小さいクラスに、大きいクラスの個数を合わせてランダムにデータを抽出する\n",
      "    idx = np.random.choice( class_data, sampling_size, replace=False)\n",
      "    downsize_class_data = data.loc[idx]\n",
      "    pd.DataFrame(downsize_class_data)\n",
      "high_frequentry_data = data[data.label == 'N'].index\n",
      "\n",
      "for label in labels:\n",
      "    class_data = df[ df.label == label ].index\n",
      "    # 出現頻度の小さいクラスに、大きいクラスの個数を合わせてランダムにデータを抽出する\n",
      "    idx = np.random.choice( class_data, sampling_size, replace=False)\n",
      "    downsize_class_data = data.loc[idx]\n",
      "    d= pd.DataFrame(downsize_class_data)\n",
      "    print(d)\n",
      "\n",
      "\n",
      "def downsize_data(data_frame, lables):\n",
      "    df = data_frame\n",
      "    sampling_size = min([ len(df[df.label == label ]) for label in labels ])    \n",
      "    sampling_idx = lambda label, sampling_size:\\\n",
      "        np.random.choice(df[ df.label == label ].index,\n",
      "                         sampling_size, replace=False)\n",
      "    sampling_data = lambda data_frame, label, sampling_size:\\\n",
      "        pd.DataFrame(data_frame.loc[sampling_idx(label, sampling_size)])\n",
      "    downsize_data = pd.concat([ sampling_data(data_frame, label, sampling_size) for label in  labels],\n",
      "                              ignore_index=True)\n",
      "    return downsize_data\n",
      "import os\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "\n",
      "labels = ['N','AB']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "\n",
      "\n",
      "df_tmp = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "\n",
      "fname_labels = [] # [ (fname, label),(),(),,, ]\n",
      "for row in df_tmp.iterrows():\n",
      "    fname = row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (fname, label)\n",
      "    fname_labels.append(d)\n",
      "\n",
      "df = pd.DataFrame(fname_labels,\n",
      "                  columns=['fname', 'label'])\n",
      "downsize_data(df, labels)\n",
      "\n",
      "\n",
      "def downsize_data(data_frame, lables):\n",
      "    df = data_frame\n",
      "    sampling_size = min([ len(df[df.label == label ]) for label in labels ])    \n",
      "    sampling_idx = lambda label, sampling_size:\\\n",
      "        np.random.choice(df[ df.label == label ].index,\n",
      "                         sampling_size, replace=False)\n",
      "    sampling_data = lambda label, sampling_size:\\\n",
      "        pd.DataFrame(df.loc[sampling_idx(label, sampling_size)])\n",
      "    downsize_data = pd.concat([ sampling_data(label, sampling_size) for label in  labels ],\n",
      "                              ignore_index=True)\n",
      "    return downsize_data\n",
      "downsize_data(df, labels)\n",
      "def downsize_data(data_frame, lables):\n",
      "    df = data_frame\n",
      "    sampling_size = min([ len(df[df.label == label ]) for label in labels ])    \n",
      "    sampling_idx = lambda label, sampling_size:\\\n",
      "        np.random.choice(df[ df.label == label ].index,\n",
      "                         sampling_size, replace=False)\n",
      "    sampling_data = lambda label, sampling_size:\\\n",
      "        pd.DataFrame(df.loc[sampling_idx(label, sampling_size)])\n",
      "    downsize_data = pd.concat([ sampling_data(label, sampling_size) for label in  labels ],\n",
      "                              ignore_index=True)\n",
      "    return downsize_data\n",
      "# (pandas.DataFrame, ['N','AB']) -> pandas.DataFrame\n",
      "def downsampling_data(data_frame, lables):\n",
      "    df = data_frame\n",
      "    sampling_size = min([ len(df[df.label == label ]) for label in labels ])    \n",
      "    sampling_idx = lambda label, sampling_size:\\\n",
      "        np.random.choice(df[ df.label == label ].index,\n",
      "                         sampling_size, replace=False)\n",
      "    sampling_data = lambda label, sampling_size:\\\n",
      "        pd.DataFrame(df.loc[sampling_idx(label, sampling_size)])\n",
      "    data = pd.concat([ sampling_data(label, sampling_size) for label in  labels ],\n",
      "                              ignore_index=True)\n",
      "    return data\n",
      "df = (df, lables)\n",
      "df = (df, labels)\n",
      "df\n",
      "import os\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "\n",
      "labels = ['N','AB']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "\n",
      "\n",
      "df_tmp = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "\n",
      "fname_labels = [] # [ (fname, label),(),(),,, ]\n",
      "for row in df_tmp.iterrows():\n",
      "    fname = row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (fname, label)\n",
      "    fname_labels.append(d)\n",
      "\n",
      "df = pd.DataFrame(fname_labels,\n",
      "                  columns=['fname', 'label'])\n",
      "df = (df, labels)\n",
      "# (pandas.DataFrame, ['N','AB']) -> pandas.DataFrame\n",
      "def downsampling_data(data_frame, lables):\n",
      "    df = data_frame\n",
      "    sampling_size = min([ len(df[df.label == label ]) for label in labels ])    \n",
      "    sampling_idx = lambda label, sampling_size:\\\n",
      "        np.random.choice(df[ df.label == label ].index,\n",
      "                         sampling_size, replace=False)\n",
      "    sampling_data = lambda label, sampling_size:\\\n",
      "        pd.DataFrame(df.loc[sampling_idx(label, sampling_size)])\n",
      "    data = pd.concat([ sampling_data(label, sampling_size) for label in  labels ],\n",
      "                              ignore_index=True)\n",
      "    return data\n",
      "df\n",
      "# (pandas.DataFrame, ['N','AB']) -> pandas.DataFrame\n",
      "def downsampling_data(data_frame, lables):\n",
      "    df = data_frame\n",
      "    sampling_size = min([ len(df[df.label == label ]) for label in labels ])    \n",
      "    sampling_idx = lambda label, sampling_size:\\\n",
      "        np.random.choice(df[ df.label == label ].index,\n",
      "                         sampling_size, replace=False)\n",
      "    sampling_data = lambda data_frame, label, sampling_size:\\\n",
      "        pd.DataFrame(data_frame.loc[sampling_idx(label, sampling_size)])\n",
      "    data = pd.concat([ sampling_data(label, sampling_size) for label in  labels ],\n",
      "                              ignore_index=True)\n",
      "    return data\n",
      "df = downsampling_data(df, labels)\n",
      "# (pandas.DataFrame, ['N','AB']) -> pandas.DataFrame\n",
      "def downsampling_data(data_frame, lables):\n",
      "    df = data_frame\n",
      "    sampling_size = min([ len(df[df.label == label ]) for label in labels ])    \n",
      "    sampling_idx = lambda label, sampling_size:\\\n",
      "        np.random.choice(df[ df.label == label ].index,\n",
      "                         sampling_size, replace=False)\n",
      "    sampling_data = lambda label, sampling_size:\\\n",
      "        pd.DataFrame(df.loc[sampling_idx(label, sampling_size)])\n",
      "    data = pd.concat([ sampling_data(label, sampling_size) for label in  labels ],\n",
      "                              ignore_index=True)\n",
      "    return data\n",
      "df = downsampling_data(df, labels)\n",
      "df = downsampling_data(df, labels)\n",
      "df = downsampling_data(df, labels)\n",
      "df\n",
      "df = downsampling_data(df, labels)\n",
      "# (pandas.DataFrame, ['N','AB']) -> pandas.DataFrame\n",
      "def downsampling_data(data_frame, lables):\n",
      "    df = data_frame\n",
      "    sampling_size = min([ len(df[df.label == label ]) for label in labels ])    \n",
      "    '''\n",
      "    sampling_idx = lambda label, sampling_size:\\\n",
      "        np.random.choice(df[ df.label == label ].index,\n",
      "                         sampling_size, replace=False)\n",
      "    sampling_data = lambda label, sampling_size:\\\n",
      "        pd.DataFrame(df.loc[sampling_idx(label, sampling_size)])\n",
      "    data = pd.concat([ sampling_data(label, sampling_size) for label in  labels ],\n",
      "                              ignore_index=True)\n",
      "    return data\n",
      "        '''\n",
      "df = downsampling_data(df, labels)\n",
      "df = downsampling_data(df, labels)\n",
      "# (pandas.DataFrame, ['N','AB']) -> pandas.DataFrame\n",
      "def downsampling_data(data_frame, lables):\n",
      "    df = data_frame\n",
      "    sampling_size = min([ len(df[df.label == label ]) for label in labels ])    \n",
      "    '''\n",
      "    sampling_idx = lambda label, sampling_size:\\\n",
      "        np.random.choice(df[ df.label == label ].index,\n",
      "                         sampling_size, replace=False)\n",
      "    sampling_data = lambda label, sampling_size:\\\n",
      "        pd.DataFrame(df.loc[sampling_idx(label, sampling_size)])\n",
      "    data = pd.concat([ sampling_data(label, sampling_size) for label in  labels ],\n",
      "                              ignore_index=True)\n",
      "    return data\n",
      "        '''\n",
      "df = downsampling_data(df, labels)\n",
      "# (pandas.DataFrame, ['N','AB']) -> pandas.DataFrame\n",
      "def downsampling_data(data_frame, lables):\n",
      "    df = data_frame\n",
      "    print(df)\n",
      "    sampling_size = min([ len(df[df.label == label ]) for label in labels ])    \n",
      "    '''\n",
      "    sampling_idx = lambda label, sampling_size:\\\n",
      "        np.random.choice(df[ df.label == label ].index,\n",
      "                         sampling_size, replace=False)\n",
      "    sampling_data = lambda label, sampling_size:\\\n",
      "        pd.DataFrame(df.loc[sampling_idx(label, sampling_size)])\n",
      "    data = pd.concat([ sampling_data(label, sampling_size) for label in  labels ],\n",
      "                              ignore_index=True)\n",
      "    return data\n",
      "        '''\n",
      "df = downsampling_data(df, labels)\n",
      "# (pandas.DataFrame, ['N','AB']) -> pandas.DataFrame\n",
      "def downsampling_data(data_frame, lables):\n",
      "    df = data_frame\n",
      "    print(dir(df))\n",
      "    sampling_size = min([ len(df[df.label == label ]) for label in labels ])    \n",
      "    '''\n",
      "    sampling_idx = lambda label, sampling_size:\\\n",
      "        np.random.choice(df[ df.label == label ].index,\n",
      "                         sampling_size, replace=False)\n",
      "    sampling_data = lambda label, sampling_size:\\\n",
      "        pd.DataFrame(df.loc[sampling_idx(label, sampling_size)])\n",
      "    data = pd.concat([ sampling_data(label, sampling_size) for label in  labels ],\n",
      "                              ignore_index=True)\n",
      "    return data\n",
      "        '''\n",
      "df = downsampling_data(df, labels)\n",
      "# (pandas.DataFrame, ['N','AB']) -> pandas.DataFrame\n",
      "def downsampling_data(data_frame, lables):\n",
      "    df = data_frame\n",
      "    print(type(df))\n",
      "    sampling_size = min([ len(df[df.label == label ]) for label in labels ])    \n",
      "    '''\n",
      "    sampling_idx = lambda label, sampling_size:\\\n",
      "        np.random.choice(df[ df.label == label ].index,\n",
      "                         sampling_size, replace=False)\n",
      "    sampling_data = lambda label, sampling_size:\\\n",
      "        pd.DataFrame(df.loc[sampling_idx(label, sampling_size)])\n",
      "    data = pd.concat([ sampling_data(label, sampling_size) for label in  labels ],\n",
      "                              ignore_index=True)\n",
      "    return data\n",
      "        '''\n",
      "df = downsampling_data(df, labels)\n",
      "type(df)\n",
      "df = downsampling_data(df, labels)\n",
      "import os\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "\n",
      "labels = ['N','AB']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "\n",
      "\n",
      "df_tmp = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "\n",
      "fname_labels = [] # [ (fname, label),(),(),,, ]\n",
      "for row in df_tmp.iterrows():\n",
      "    fname = row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (fname, label)\n",
      "    fname_labels.append(d)\n",
      "\n",
      "df = pd.DataFrame(fname_labels,\n",
      "                  columns=['fname', 'label'])\n",
      "type(df)\n",
      "df = downsampling_data(df, labels)\n",
      "type(df)\n",
      "df = downsampling_data(df, labels)\n",
      "import os\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "\n",
      "labels = ['N','AB']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "\n",
      "\n",
      "df_tmp = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "\n",
      "fname_labels = [] # [ (fname, label),(),(),,, ]\n",
      "for row in df_tmp.iterrows():\n",
      "    fname = row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (fname, label)\n",
      "    fname_labels.append(d)\n",
      "\n",
      "df = pd.DataFrame(fname_labels,\n",
      "                  columns=['fname', 'label'])\n",
      "type(df)\n",
      "df = downsampling_data(df, labels)\n",
      "import os\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "\n",
      "labels = ['N','AB']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "\n",
      "\n",
      "df_tmp = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "\n",
      "fname_labels = [] # [ (fname, label),(),(),,, ]\n",
      "for row in df_tmp.iterrows():\n",
      "    fname = row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (fname, label)\n",
      "    fname_labels.append(d)\n",
      "\n",
      "df = pd.DataFrame(fname_labels,\n",
      "                  columns=['fname', 'label'])\n",
      "type(df)\n",
      "df = downsampling_data(df, labels)\n",
      "df\n",
      "df\n",
      "df\n",
      "type(df)\n",
      "import os\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "\n",
      "labels = ['N','AB']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "\n",
      "\n",
      "df_tmp = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "\n",
      "fname_labels = [] # [ (fname, label),(),(),,, ]\n",
      "for row in df_tmp.iterrows():\n",
      "    fname = row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (fname, label)\n",
      "    fname_labels.append(d)\n",
      "\n",
      "df = pd.DataFrame(fname_labels,\n",
      "                  columns=['fname', 'label'])\n",
      "type(df)\n",
      "df = downsampling_data(df, labels)\n",
      "# (pandas.DataFrame, ['N','AB']) -> pandas.DataFrame\n",
      "def downsampling_data(data_frame, lables):\n",
      "    df = data_frame\n",
      "    sampling_size = min([ len(df[df.label == label ]) for label in labels ])    \n",
      "    #'''\n",
      "    sampling_idx = lambda label, sampling_size:\\\n",
      "        np.random.choice(df[ df.label == label ].index,\n",
      "                         sampling_size, replace=False)\n",
      "    sampling_data = lambda label, sampling_size:\\\n",
      "        pd.DataFrame(df.loc[sampling_idx(label, sampling_size)])\n",
      "    data = pd.concat([ sampling_data(label, sampling_size) for label in  labels ],\n",
      "                              ignore_index=True)\n",
      "    return data\n",
      "    #    '''\n",
      "type(df)\n",
      "# (pandas.DataFrame, ['N','AB']) -> pandas.DataFrame\n",
      "def downsampling_data(data_frame, lables):\n",
      "    df = data_frame\n",
      "    sampling_size = min([ len(df[df.label == label ]) for label in labels ])    \n",
      "    #'''\n",
      "    sampling_idx = lambda label, sampling_size:\\\n",
      "        np.random.choice(df[ df.label == label ].index,\n",
      "                         sampling_size, replace=False)\n",
      "    print(sampling_idx)\n",
      "    sampling_data = lambda label, sampling_size:\\\n",
      "        pd.DataFrame(df.loc[sampling_idx(label, sampling_size)])\n",
      "    data = pd.concat([ sampling_data(label, sampling_size) for label in  labels ],\n",
      "                              ignore_index=True)\n",
      "    return data\n",
      "    #    '''\n",
      "import os\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "\n",
      "labels = ['N','AB']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "\n",
      "\n",
      "df_tmp = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "\n",
      "fname_labels = [] # [ (fname, label),(),(),,, ]\n",
      "for row in df_tmp.iterrows():\n",
      "    fname = row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (fname, label)\n",
      "    fname_labels.append(d)\n",
      "\n",
      "df = pd.DataFrame(fname_labels,\n",
      "                  columns=['fname', 'label'])\n",
      "type(df)\n",
      "df = downsampling_data(df, labels)\n",
      "import os\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "\n",
      "labels = ['N','AB']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "\n",
      "\n",
      "df_tmp = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "\n",
      "fname_labels = [] # [ (fname, label),(),(),,, ]\n",
      "for row in df_tmp.iterrows():\n",
      "    fname = row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (fname, label)\n",
      "    fname_labels.append(d)\n",
      "\n",
      "df = pd.DataFrame(fname_labels,\n",
      "                  columns=['fname', 'label'])\n",
      "type(df)\n",
      "df = downsampling_data(df, labels)\n",
      "df\n",
      "import os\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "\n",
      "labels = ['N','AB']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "\n",
      "\n",
      "df_tmp = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "\n",
      "fname_labels = [] # [ (fname, label),(),(),,, ]\n",
      "for row in df_tmp.iterrows():\n",
      "    fname = row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (fname, label)\n",
      "    fname_labels.append(d)\n",
      "\n",
      "df = pd.DataFrame(fname_labels,\n",
      "                  columns=['fname', 'label'])\n",
      "\n",
      "\n",
      "# (pandas.DataFrame, ['N','AB']) -> pandas.DataFrame\n",
      "def downsampling_data(data_frame, lables):\n",
      "    df = data_frame\n",
      "    sampling_size = min([ len(df[df.label == label ]) for label in labels ])    \n",
      "    #'''\n",
      "    sampling_idx = lambda label, sampling_size:\\\n",
      "        np.random.choice(df[ df.label == label ].index,\n",
      "                         sampling_size, replace=False)\n",
      "    print(sampling_idx)\n",
      "    sampling_data = lambda label, sampling_size:\\\n",
      "        pd.DataFrame(df.loc[sampling_idx(label, sampling_size)])\n",
      "    data = pd.concat([ sampling_data(label, sampling_size) for label in  labels ],\n",
      "                              ignore_index=True)\n",
      "    return data\n",
      "    #    '''\n",
      "\n",
      "df = downsampling_data(df, labels)\n",
      "import os\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "\n",
      "labels = ['N','AB']\n",
      "\n",
      "try:\n",
      "    os.mkdir(data_dir)\n",
      "except:\n",
      "    pass\n",
      "for label in labels:\n",
      "    try:\n",
      "        os.mkdir(data_dir+label)\n",
      "    except:\n",
      "        pass\n",
      "\n",
      "\n",
      "df_tmp = pd.read_csv(eyes_results,\n",
      "                 delimiter='\\t', header=None).dropna()\n",
      "\n",
      "fname_labels = [] # [ (fname, label),(),(),,, ]\n",
      "for row in df_tmp.iterrows():\n",
      "    fname = row[1][0] + '.JPG'\n",
      "    label = 'N' if row[1][2]=='[\"異常なし\"]' else 'AB'\n",
      "    d = (fname, label)\n",
      "    fname_labels.append(d)\n",
      "\n",
      "df = pd.DataFrame(fname_labels,\n",
      "                  columns=['fname', 'label'])\n",
      "\n",
      "\n",
      "# (pandas.DataFrame, ['N','AB']) -> pandas.DataFrame\n",
      "def downsampling_data(data_frame, lables):\n",
      "    df = data_frame\n",
      "    sampling_size = min([ len(df[df.label == label ]) for label in labels ])    \n",
      "    #'''\n",
      "    sampling_idx = lambda label, sampling_size:\\\n",
      "        np.random.choice(df[ df.label == label ].index,\n",
      "                         sampling_size, replace=False)\n",
      "    sampling_data = lambda label, sampling_size:\\\n",
      "        pd.DataFrame(df.loc[sampling_idx(label, sampling_size)])\n",
      "    data = pd.concat([ sampling_data(label, sampling_size) for label in  labels ],\n",
      "                              ignore_index=True)\n",
      "    return data\n",
      "    #    '''\n",
      "\n",
      "df = downsampling_data(df, labels)\n",
      "#sampling_size = min([ len(df[df.label == label ]) for label in labels ])    \n",
      "df[df.label == 'N']\n",
      "#sampling_size = min([ len(df[df.label == label ]) for label in labels ])    \n",
      "class_data = df[df.label == 'N'][len(class_data)//10:]\n",
      "#sampling_size = min([ len(df[df.label == label ]) for label in labels ])    \n",
      "class_data = df[df.label == 'N'][len(class_data)//10:]\n",
      "class_data\n",
      "#sampling_size = min([ len(df[df.label == label ]) for label in labels ])    \n",
      "class_data = df[df.label == 'N']#[len(class_data)//10:]\n",
      "class_data\n",
      "#sampling_size = min([ len(df[df.label == label ]) for label in labels ])\n",
      "\n",
      "for label in labels:\n",
      "    validation_data = df[df.label == label][:len(class_data)//10]\n",
      "    test_data = df[df.label == label][len(class_data)//10:]\n",
      "    for (fname, label) in test_data:\n",
      "        print(fname, label\n",
      "#sampling_size = min([ len(df[df.label == label ]) for label in labels ])\n",
      "\n",
      "for label in labels:\n",
      "    validation_data = df[df.label == label][:len(class_data)//10]\n",
      "    test_data = df[df.label == label][len(class_data)//10:]\n",
      "    for (fname, label) in test_data:\n",
      "        print(fname, label)\n",
      "#sampling_size = min([ len(df[df.label == label ]) for label in labels ])\n",
      "\n",
      "for label in labels:\n",
      "    validation_data = df[df.label == label][:len(class_data)//10]\n",
      "    test_data = df[df.label == label][len(class_data)//10:]\n",
      "    for (fname, label) in test_data.iterrows():\n",
      "        print(fname, label)\n",
      "#sampling_size = min([ len(df[df.label == label ]) for label in labels ])\n",
      "\n",
      "for label in labels:\n",
      "    validation_data = df[df.label == label][:len(class_data)//10]\n",
      "    test_data = df[df.label == label][len(class_data)//10:]\n",
      "    for (fname, label) in test_data.iterrows():\n",
      "        read_fname = eyes_dir + fname\n",
      "        write_fname = eyes_dir + label + '/' + fname\n",
      "\n",
      "        print(read_fname, write_fname, label)\n",
      "#sampling_size = min([ len(df[df.label == label ]) for label in labels ])\n",
      "\n",
      "for label in labels:\n",
      "    validation_data = df[df.label == label][:len(class_data)//10]\n",
      "    test_data = df[df.label == label][len(class_data)//10:]\n",
      "    for (fname, label) in test_data.iterrows():\n",
      "        print(fname)\n",
      "        read_fname = eyes_dir + fname\n",
      "        write_fname = eyes_dir + label + '/' + fname\n",
      "\n",
      "        print(read_fname, write_fname, label)\n",
      "#sampling_size = min([ len(df[df.label == label ]) for label in labels ])\n",
      "\n",
      "for label in labels:\n",
      "    validation_data = df[df.label == label][:len(class_data)//10]\n",
      "    test_data = df[df.label == label][len(class_data)//10:]\n",
      "    for (fname, label) in test_data.iterrows():\n",
      "        print(type(fname))\n",
      "        read_fname = eyes_dir + fname\n",
      "        write_fname = eyes_dir + label + '/' + fname\n",
      "\n",
      "        print(read_fname, write_fname, label)\n",
      "#sampling_size = min([ len(df[df.label == label ]) for label in labels ])\n",
      "\n",
      "for label in labels:\n",
      "    validation_data = df[df.label == label][:len(class_data)//10]\n",
      "    test_data = df[df.label == label][len(class_data)//10:]\n",
      "    for d in test_data.iterrows():\n",
      "        print(type(d))\n",
      "        read_fname = eyes_dir + fname\n",
      "        write_fname = eyes_dir + label + '/' + fname\n",
      "\n",
      "        print(read_fname, write_fname, label)\n",
      "#sampling_size = min([ len(df[df.label == label ]) for label in labels ])\n",
      "\n",
      "for label in labels:\n",
      "    validation_data = df[df.label == label][:len(class_data)//10]\n",
      "    test_data = df[df.label == label][len(class_data)//10:]\n",
      "    for d in test_data.iterrows():\n",
      "        print(d)\n",
      "        read_fname = eyes_dir + fname\n",
      "        write_fname = eyes_dir + label + '/' + fname\n",
      "\n",
      "        print(read_fname, write_fname, label)\n",
      "#sampling_size = min([ len(df[df.label == label ]) for label in labels ])\n",
      "\n",
      "for label in labels:\n",
      "    validation_data = df[df.label == label][:len(class_data)//10]\n",
      "    test_data = df[df.label == label][len(class_data)//10:]\n",
      "    for d in test_data.iterrows():\n",
      "        fname = d[1][0]\n",
      "        read_fname = eyes_dir + fname\n",
      "        write_fname = eyes_dir + label + '/' + fname\n",
      "\n",
      "        print(read_fname, write_fname, label)\n",
      "#sampling_size = min([ len(df[df.label == label ]) for label in labels ])\n",
      "\n",
      "for label in labels:\n",
      "    validation_data = df[df.label == label][:len(class_data)//10]\n",
      "    train_data = df[df.label == label][len(class_data)//10:]\n",
      "    for d in validation_data.iterrows():\n",
      "        fname = d[1][0]\n",
      "        read_fname = eyes_dir + fname\n",
      "        write_fname = eyes_dir + 'validation/' + label + '/' + fname\n",
      "\n",
      "        print(read_fname, write_fname, label)\n",
      "    for d in train_data.iterrows():\n",
      "        fname = d[1][0]\n",
      "        read_fname = eyes_dir + fname\n",
      "        write_fname = eyes_dir + 'train/' + label + '/' + fname\n",
      "\n",
      "        print(read_fname, write_fname, label)\n",
      "def mkdir(dir_name):\n",
      "    try:\n",
      "        os.mkdir(dir_name)\n",
      "    except:\n",
      "        pass\n",
      "mkdir(data_dir)\n",
      "mkdir(data_dir+'train/')\n",
      "mkdir(data_dir+'validation/')\n",
      "[ mkdir(data_dir+'train/'+label) for label in labels ]\n",
      "[ mkdir(data_dir+'validaiton/'+label) for label in labels ]\n",
      "df\n",
      "df['lable']\n",
      "df['labe;']\n",
      "df['label']\n",
      "import os\n",
      "import pandas as pd\n",
      "\n",
      "eyes_results = '../micin/ynzw_result.csv.tsv'\n",
      "eyes_dir = '../micin/eyes/'\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "\n",
      "labels = ['N','AB']\n",
      "\n",
      "\n",
      "def mkdir(dir_name):\n",
      "    try:\n",
      "        os.mkdir(dir_name)\n",
      "    except:\n",
      "        pass\n",
      "mkdir(data_dir)\n",
      "mkdir(data_dir+'train/')\n",
      "mkdir(data_dir+'validation/')\n",
      "[ mkdir(data_dir+'train/'+label) for label in labels ]\n",
      "[ mkdir(data_dir+'validaiton/'+label) for label in labels ]\n",
      "\n",
      "\n",
      "df_tmp = pd.read_csv(eyes_results,\n",
      "                     delimiter='\\t', header=None).dropna()\n",
      "\n",
      "# (pandas.DataFrame, ['N','AB']) -> pandas.DataFrame\n",
      "def downsampling_data(data_frame, lables):\n",
      "    df = data_frame\n",
      "    sampling_size = min([ len(df[df.label == label ]) for label in labels ])    \n",
      "    #'''\n",
      "    sampling_idx = lambda label, sampling_size:\\\n",
      "        np.random.choice(df[ df.label == label ].index,\n",
      "                         sampling_size, replace=False)\n",
      "    sampling_data = lambda label, sampling_size:\\\n",
      "        pd.DataFrame(df.loc[sampling_idx(label, sampling_size)])\n",
      "    data = pd.concat([ sampling_data(label, sampling_size) for label in  labels ],\n",
      "                              ignore_index=True)\n",
      "    return data\n",
      "    #    '''\n",
      "df_tmp = pd.read_csv(eyes_results,\n",
      "                     delimiter='\\t', header=None).dropna()\n",
      "\n",
      "df = downsampling_data(df, labels)\n",
      "df\n",
      "#sampling_size = min([ len(df[df.label == label ]) for label in labels ])\n",
      "\n",
      "for label in labels:\n",
      "    class_data = df[df.label == label]\n",
      "    validation_data = class_data[:len(class_data)//10]\n",
      "    train_data = class_data[len(class_data)//10:]\n",
      "    for d in validation_data.iterrows():\n",
      "        fname = d[1][0]\n",
      "        read_fname = eyes_dir + fname\n",
      "        write_fname = eyes_dir + 'validation/' + label + '/' + fname\n",
      "        print( read_fname, read_fname )\n",
      "        #open(write_fname, 'wb').write(open(read_fname,'rb').read())\n",
      "    for d in train_data.iterrows():\n",
      "        fname = d[1][0]\n",
      "        read_fname = eyes_dir + fname\n",
      "        write_fname = eyes_dir + 'train/' + label + '/' + fname\n",
      "        print( read_fname, read_fname )\n",
      "        #open(write_fname, 'wb').write(open(read_fname,'rb').read())\n",
      "#sampling_size = min([ len(df[df.label == label ]) for label in labels ])\n",
      "\n",
      "for label in labels:\n",
      "    class_data = df[df.label == label]\n",
      "    validation_data = class_data[:len(class_data)//10]\n",
      "    train_data = class_data[len(class_data)//10:]\n",
      "    for d in validation_data.iterrows():\n",
      "        fname = d[1][0]\n",
      "        read_fname = eyes_dir + fname\n",
      "        write_fname = eyes_dir + 'validation/' + label + '/' + fname\n",
      "        print( read_fname, write_fname )\n",
      "        #open(write_fname, 'wb').write(open(read_fname,'rb').read())\n",
      "    for d in train_data.iterrows():\n",
      "        fname = d[1][0]\n",
      "        read_fname = eyes_dir + fname\n",
      "        write_fname = eyes_dir + 'train/' + label + '/' + fname\n",
      "        print( read_fname, write_fname )\n",
      "        #open(write_fname, 'wb').write(open(read_fname,'rb').read())\n",
      "#sampling_size = min([ len(df[df.label == label ]) for label in labels ])\n",
      "\n",
      "for label in labels:\n",
      "    class_data = df[df.label == label]\n",
      "    validation_data = class_data[:len(class_data)//10]\n",
      "    train_data = class_data[len(class_data)//10:]\n",
      "    for d in validation_data.iterrows():\n",
      "        fname = d[1][0]\n",
      "        read_fname = eyes_dir + fname\n",
      "        write_fname = eyes_dir + 'validation/' + label + '/' + fname\n",
      "        open(write_fname, 'wb').write(open(read_fname,'rb').read())\n",
      "    for d in train_data.iterrows():\n",
      "        fname = d[1][0]\n",
      "        read_fname = eyes_dir + fname\n",
      "        write_fname = eyes_dir + 'train/' + label + '/' + fname\n",
      "        print( read_fname, write_fname )\n",
      "        #open(write_fname, 'wb').write(open(read_fname,'rb').read())\n",
      "#sampling_size = min([ len(df[df.label == label ]) for label in labels ])\n",
      "\n",
      "for label in labels:\n",
      "    class_data = df[df.label == label]\n",
      "    validation_data = class_data[:len(class_data)//10]\n",
      "    train_data = class_data[len(class_data)//10:]\n",
      "    for d in validation_data.iterrows():\n",
      "        fname = d[1][0]\n",
      "        read_fname = eyes_dir + fname\n",
      "        write_fname = eyes_dir + 'validation/' + label + '/' + fname\n",
      "        f = open(read_fname,'rb').read()\n",
      "        open(write_fname, 'wb').write(f)\n",
      "    for d in train_data.iterrows():\n",
      "        fname = d[1][0]\n",
      "        read_fname = eyes_dir + fname\n",
      "        write_fname = eyes_dir + 'train/' + label + '/' + fname\n",
      "        print( read_fname, write_fname )\n",
      "        #open(write_fname, 'wb').write(open(read_fname,'rb').read())\n",
      "open('test.txt''w').write('eee')\n",
      "open('test.txt','w').write('eee')\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "train_datagen = ImageDataGenerator(\n",
      "        rescale=1./255,\n",
      "        shear_range=0.2,\n",
      "        zoom_range=0.2,\n",
      "        horizontal_flip=True)\n",
      "\n",
      "test_datagen = ImageDataGenerator(rescale=1./255)\n",
      "\n",
      "train_generator = train_datagen.flow_from_directory(\n",
      "        data_dir + 'train',\n",
      "        target_size=(150, 150),\n",
      "        batch_size=32,\n",
      "        class_mode='binary')\n",
      "\n",
      "validation_generator = test_datagen.flow_from_directory(\n",
      "        data_dir + 'validation',\n",
      "        target_size=(150, 150),\n",
      "        batch_size=32,\n",
      "        class_mode='binary')\n",
      "\n",
      "model.fit_generator(\n",
      "        train_generator,\n",
      "        steps_per_epoch=2000,\n",
      "        epochs=50,\n",
      "        validation_data=validation_generator,\n",
      "        validation_steps=800)\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Convolution2D, MaxPooling2D\n",
      "from keras.layers import Activation, Dropout, Flatten, Dense\n",
      "from keras.preprocessing.image import ImageDataGenerator\n",
      "\n",
      "\n",
      "batch_size = 32\n",
      "epochs = 1\n",
      "\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Convolution2D(32, 3, 3, input_shape=(128, 128, 3)))\n",
      "model.add(Activation('relu'))\n",
      "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
      "\n",
      "model.add(Convolution2D(64, 3, 3))\n",
      "model.add(Activation('relu'))\n",
      "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
      "\n",
      "model.add(Flatten())\n",
      "model.add(Dense(64))\n",
      "model.add(Activation('relu'))\n",
      "model.add(Dropout(0.5))\n",
      "model.add(Dense(2))\n",
      "model.add(Activation('softmax'))\n",
      "\n",
      "model.summary()\n",
      "\n",
      "model.compile(loss='categorical_crossentropy',\n",
      "               optimizer='adam',\n",
      "               metrics=['accuracy'])\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "train_datagen = ImageDataGenerator(\n",
      "        rescale=1./255,\n",
      "        shear_range=0.2,\n",
      "        zoom_range=0.2,\n",
      "        horizontal_flip=True)\n",
      "\n",
      "test_datagen = ImageDataGenerator(rescale=1./255)\n",
      "\n",
      "train_generator = train_datagen.flow_from_directory(\n",
      "        data_dir + 'train',\n",
      "        target_size=(150, 150),\n",
      "        batch_size=32,\n",
      "        class_mode='binary')\n",
      "\n",
      "validation_generator = test_datagen.flow_from_directory(\n",
      "        data_dir + 'validation',\n",
      "        target_size=(150, 150),\n",
      "        batch_size=32,\n",
      "        class_mode='binary')\n",
      "\n",
      "model.fit_generator(\n",
      "        train_generator,\n",
      "        steps_per_epoch=2000,\n",
      "        epochs=50,\n",
      "        validation_data=validation_generator,\n",
      "        validation_steps=800)\n",
      "data_dir = '../data/eyes/'\n",
      "\n",
      "train_datagen = ImageDataGenerator(\n",
      "    rescale=1.0 / 255,\n",
      "    shear_range=0.2,\n",
      "    zoom_range=0.2,\n",
      "    horizontal_flip=True)\n",
      "\n",
      "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
      "\n",
      "\n",
      "train_generator = train_datagen.flow_from_directory(\n",
      "    data_dir + 'train',\n",
      "    target_size=(128, 128),\n",
      "    batch_size=batch_size,\n",
      "    class_mode='categorical')\n",
      "\n",
      "validation_generator = test_datagen.flow_from_directory(\n",
      "    data_dir + 'validation',\n",
      "    target_size=(128, 128),\n",
      "    batch_size=batch_size,\n",
      "    class_mode='categorical')\n",
      "\n",
      "\n",
      "history = model.fit_generator(\n",
      "    train_generator,\n",
      "    samples_per_epoch=200,\n",
      "    nb_epoch=epochs,\n",
      "    validation_data=validation_generator,\n",
      "    nb_val_samples=200)\n",
      "history\n"
     ]
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('test.txt','w').write('eee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (pandas.DataFrame, ['N','AB']) -> [pandas.DataFrame]\n",
    "# tv_rate : ratio of the data size of train vs validation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "flow() got an unexpected keyword argument 'target_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-0f9b12bd9c8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#class_mode='categorical'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: flow() got an unexpected keyword argument 'target_size'"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow(\n",
    "    x_train, y_train,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=30,\n",
    "    #class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../micin/brain/PS116.jpg ../data/brain/PS/PS116.jpg\n",
      "../micin/brain/PD096.jpg ../data/brain/PD/PD096.jpg\n",
      "../micin/brain/PD062.jpg ../data/brain/PD/PD062.jpg\n",
      "../micin/brain/PD002.jpg ../data/brain/PD/PD002.jpg\n",
      "../micin/brain/PD045.jpg ../data/brain/PD/PD045.jpg\n",
      "../micin/brain/PS80.jpg ../data/brain/PS/PS80.jpg\n",
      "../micin/brain/MS136.jpg ../data/brain/MS/MS136.jpg\n",
      "../micin/brain/PD061.jpg ../data/brain/PD/PD061.jpg\n",
      "../micin/brain/PS102.jpg ../data/brain/PS/PS102.jpg\n",
      "../micin/brain/MS162.jpg ../data/brain/MS/MS162.jpg\n",
      "../micin/brain/N070.jpg ../data/brain/N/N070.jpg\n",
      "../micin/brain/PS018.jpg ../data/brain/PS/PS018.jpg\n",
      "../micin/brain/PS118.jpg ../data/brain/PS/PS118.jpg\n",
      "../micin/brain/PS041.jpg ../data/brain/PS/PS041.jpg\n",
      "../micin/brain/PD046.jpg ../data/brain/PD/PD046.jpg\n",
      "../micin/brain/PS028.jpg ../data/brain/PS/PS028.jpg\n",
      "../micin/brain/PS112.jpg ../data/brain/PS/PS112.jpg\n",
      "../micin/brain/PS031.jpg ../data/brain/PS/PS031.jpg\n",
      "../micin/brain/PS050.jpg ../data/brain/PS/PS050.jpg\n",
      "../micin/brain/PS012.jpg ../data/brain/PS/PS012.jpg\n",
      "../micin/brain/N123.jpg ../data/brain/N/N123.jpg\n",
      "../micin/brain/N050.jpg ../data/brain/N/N050.jpg\n",
      "../micin/brain/MS140.jpg ../data/brain/MS/MS140.jpg\n",
      "../micin/brain/N006.jpg ../data/brain/N/N006.jpg\n",
      "../micin/brain/PD020.jpg ../data/brain/PD/PD020.jpg\n",
      "../micin/brain/N124.jpg ../data/brain/N/N124.jpg\n",
      "../micin/brain/PS101.jpg ../data/brain/PS/PS101.jpg\n",
      "../micin/brain/PS127.jpg ../data/brain/PS/PS127.jpg\n",
      "../micin/brain/PD057.jpg ../data/brain/PD/PD057.jpg\n",
      "../micin/brain/MS114.jpg ../data/brain/MS/MS114.jpg\n",
      "../micin/brain/MS163.jpg ../data/brain/MS/MS163.jpg\n",
      "../micin/brain/MS168.jpg ../data/brain/MS/MS168.jpg\n",
      "../micin/brain/PD138.jpg ../data/brain/PD/PD138.jpg\n",
      "../micin/brain/PD040.jpg ../data/brain/PD/PD040.jpg\n",
      "../micin/brain/N022.jpg ../data/brain/N/N022.jpg\n",
      "../micin/brain/N035.jpg ../data/brain/N/N035.jpg\n",
      "../micin/brain/N119.jpg ../data/brain/N/N119.jpg\n",
      "../micin/brain/PD094.jpg ../data/brain/PD/PD094.jpg\n",
      "../micin/brain/MS105.jpg ../data/brain/MS/MS105.jpg\n",
      "../micin/brain/PS124.jpg ../data/brain/PS/PS124.jpg\n",
      "../micin/brain/N155.jpg ../data/brain/N/N155.jpg\n",
      "../micin/brain/PS069.jpg ../data/brain/PS/PS069.jpg\n",
      "../micin/brain/MS142.jpg ../data/brain/MS/MS142.jpg\n",
      "../micin/brain/PS062.jpg ../data/brain/PS/PS062.jpg\n",
      "../micin/brain/PS82.jpg ../data/brain/PS/PS82.jpg\n",
      "../micin/brain/PS043.jpg ../data/brain/PS/PS043.jpg\n",
      "../micin/brain/PD136.jpg ../data/brain/PD/PD136.jpg\n",
      "../micin/brain/PD114.jpg ../data/brain/PD/PD114.jpg\n",
      "../micin/brain/N068.jpg ../data/brain/N/N068.jpg\n",
      "../micin/brain/PS064.jpg ../data/brain/PS/PS064.jpg\n",
      "../micin/brain/PS001.jpg ../data/brain/PS/PS001.jpg\n",
      "../micin/brain/PD015.jpg ../data/brain/PD/PD015.jpg\n",
      "../micin/brain/PS036.jpg ../data/brain/PS/PS036.jpg\n",
      "../micin/brain/PS110.jpg ../data/brain/PS/PS110.jpg\n",
      "../micin/brain/MS160.jpg ../data/brain/MS/MS160.jpg\n",
      "../micin/brain/N032.jpg ../data/brain/N/N032.jpg\n",
      "../micin/brain/PS010.jpg ../data/brain/PS/PS010.jpg\n",
      "../micin/brain/N096.jpg ../data/brain/N/N096.jpg\n",
      "../micin/brain/PS85.jpg ../data/brain/PS/PS85.jpg\n",
      "../micin/brain/N078.jpg ../data/brain/N/N078.jpg\n",
      "../micin/brain/PD064.jpg ../data/brain/PD/PD064.jpg\n",
      "../micin/brain/MS125.jpg ../data/brain/MS/MS125.jpg\n",
      "../micin/brain/N010.jpg ../data/brain/N/N010.jpg\n",
      "../micin/brain/N133.jpg ../data/brain/N/N133.jpg\n",
      "../micin/brain/PS83.jpg ../data/brain/PS/PS83.jpg\n",
      "../micin/brain/PD101.jpg ../data/brain/PD/PD101.jpg\n",
      "../micin/brain/N111.jpg ../data/brain/N/N111.jpg\n",
      "../micin/brain/N042.jpg ../data/brain/N/N042.jpg\n",
      "../micin/brain/PD051.jpg ../data/brain/PD/PD051.jpg\n",
      "../micin/brain/N015.jpg ../data/brain/N/N015.jpg\n",
      "../micin/brain/PS052.jpg ../data/brain/PS/PS052.jpg\n",
      "../micin/brain/N024.jpg ../data/brain/N/N024.jpg\n",
      "../micin/brain/N071.jpg ../data/brain/N/N071.jpg\n",
      "../micin/brain/N059.jpg ../data/brain/N/N059.jpg\n",
      "../micin/brain/MS126.jpg ../data/brain/MS/MS126.jpg\n",
      "../micin/brain/MS052.jpg ../data/brain/MS/MS052.jpg\n",
      "../micin/brain/MS87.jpg ../data/brain/MS/MS87.jpg\n",
      "../micin/brain/PD043.jpg ../data/brain/PD/PD043.jpg\n",
      "../micin/brain/PD077.jpg ../data/brain/PD/PD077.jpg\n",
      "../micin/brain/N004.jpg ../data/brain/N/N004.jpg\n",
      "../micin/brain/PD111.jpg ../data/brain/PD/PD111.jpg\n",
      "../micin/brain/N100.jpg ../data/brain/N/N100.jpg\n",
      "../micin/brain/N005.jpg ../data/brain/N/N005.jpg\n",
      "../micin/brain/PS115.jpg ../data/brain/PS/PS115.jpg\n",
      "../micin/brain/MS122.jpg ../data/brain/MS/MS122.jpg\n",
      "../micin/brain/PD099.jpg ../data/brain/PD/PD099.jpg\n",
      "../micin/brain/PS119.jpg ../data/brain/PS/PS119.jpg\n",
      "../micin/brain/N120.jpg ../data/brain/N/N120.jpg\n",
      "../micin/brain/PD059.jpg ../data/brain/PD/PD059.jpg\n",
      "../micin/brain/PD102.jpg ../data/brain/PD/PD102.jpg\n",
      "../micin/brain/PD070.jpg ../data/brain/PD/PD070.jpg\n",
      "../micin/brain/PD048.jpg ../data/brain/PD/PD048.jpg\n",
      "../micin/brain/N023.jpg ../data/brain/N/N023.jpg\n",
      "../micin/brain/N033.jpg ../data/brain/N/N033.jpg\n",
      "../micin/brain/PS73.jpg ../data/brain/PS/PS73.jpg\n",
      "../micin/brain/MS119.jpg ../data/brain/MS/MS119.jpg\n",
      "../micin/brain/PD079.jpg ../data/brain/PD/PD079.jpg\n",
      "../micin/brain/N160.jpg ../data/brain/N/N160.jpg\n",
      "../micin/brain/PS034.jpg ../data/brain/PS/PS034.jpg\n",
      "../micin/brain/PS113.jpg ../data/brain/PS/PS113.jpg\n",
      "../micin/brain/PS015.jpg ../data/brain/PS/PS015.jpg\n",
      "../micin/brain/MS102.jpg ../data/brain/MS/MS102.jpg\n",
      "../micin/brain/MS141.jpg ../data/brain/MS/MS141.jpg\n",
      "../micin/brain/N074.jpg ../data/brain/N/N074.jpg\n",
      "../micin/brain/N057.jpg ../data/brain/N/N057.jpg\n",
      "../micin/brain/PS96.jpg ../data/brain/PS/PS96.jpg\n",
      "../micin/brain/N061.jpg ../data/brain/N/N061.jpg\n",
      "../micin/brain/MS133.jpg ../data/brain/MS/MS133.jpg\n",
      "../micin/brain/PS016.jpg ../data/brain/PS/PS016.jpg\n",
      "../micin/brain/N065.jpg ../data/brain/N/N065.jpg\n",
      "../micin/brain/MS118.jpg ../data/brain/MS/MS118.jpg\n",
      "../micin/brain/N093.jpg ../data/brain/N/N093.jpg\n",
      "../micin/brain/PS058.jpg ../data/brain/PS/PS058.jpg\n",
      "../micin/brain/PD037.jpg ../data/brain/PD/PD037.jpg\n",
      "../micin/brain/N007.jpg ../data/brain/N/N007.jpg\n",
      "../micin/brain/MS116.jpg ../data/brain/MS/MS116.jpg\n",
      "../micin/brain/N140.jpg ../data/brain/N/N140.jpg\n",
      "../micin/brain/MS123.jpg ../data/brain/MS/MS123.jpg\n",
      "../micin/brain/N054.jpg ../data/brain/N/N054.jpg\n",
      "../micin/brain/MS83.jpg ../data/brain/MS/MS83.jpg\n",
      "../micin/brain/PD103.jpg ../data/brain/PD/PD103.jpg\n",
      "../micin/brain/N002.jpg ../data/brain/N/N002.jpg\n",
      "../micin/brain/PD025.jpg ../data/brain/PD/PD025.jpg\n",
      "../micin/brain/MS120.jpg ../data/brain/MS/MS120.jpg\n",
      "../micin/brain/MS164.jpg ../data/brain/MS/MS164.jpg\n",
      "../micin/brain/PS070.jpg ../data/brain/PS/PS070.jpg\n",
      "../micin/brain/N144.jpg ../data/brain/N/N144.jpg\n",
      "../micin/brain/MS127.jpg ../data/brain/MS/MS127.jpg\n",
      "../micin/brain/MS167.jpg ../data/brain/MS/MS167.jpg\n",
      "../micin/brain/MS135.jpg ../data/brain/MS/MS135.jpg\n",
      "../micin/brain/N135.jpg ../data/brain/N/N135.jpg\n",
      "../micin/brain/PS79.jpg ../data/brain/PS/PS79.jpg\n",
      "../micin/brain/PS126.jpg ../data/brain/PS/PS126.jpg\n",
      "../micin/brain/MS060.jpg ../data/brain/MS/MS060.jpg\n",
      "../micin/brain/PD092.jpg ../data/brain/PD/PD092.jpg\n",
      "../micin/brain/PS002.jpg ../data/brain/PS/PS002.jpg\n",
      "../micin/brain/N098.jpg ../data/brain/N/N098.jpg\n",
      "../micin/brain/MS068.jpg ../data/brain/MS/MS068.jpg\n",
      "../micin/brain/N079.jpg ../data/brain/N/N079.jpg\n",
      "../micin/brain/N053.jpg ../data/brain/N/N053.jpg\n",
      "../micin/brain/MS132.jpg ../data/brain/MS/MS132.jpg\n",
      "../micin/brain/N011.jpg ../data/brain/N/N011.jpg\n",
      "../micin/brain/N150.jpg ../data/brain/N/N150.jpg\n",
      "../micin/brain/N115.jpg ../data/brain/N/N115.jpg\n",
      "../micin/brain/N025.jpg ../data/brain/N/N025.jpg\n",
      "../micin/brain/PS047.jpg ../data/brain/PS/PS047.jpg\n",
      "../micin/brain/PS75.jpg ../data/brain/PS/PS75.jpg\n",
      "../micin/brain/PD108.jpg ../data/brain/PD/PD108.jpg\n",
      "../micin/brain/N146.jpg ../data/brain/N/N146.jpg\n",
      "../micin/brain/N019.jpg ../data/brain/N/N019.jpg\n",
      "../micin/brain/MS131.jpg ../data/brain/MS/MS131.jpg\n",
      "../micin/brain/PD089.jpg ../data/brain/PD/PD089.jpg\n",
      "../micin/brain/PD038.jpg ../data/brain/PD/PD038.jpg\n",
      "../micin/brain/MS100.jpg ../data/brain/MS/MS100.jpg\n",
      "../micin/brain/N037.jpg ../data/brain/N/N037.jpg\n",
      "../micin/brain/MS058.jpg ../data/brain/MS/MS058.jpg\n",
      "../micin/brain/N051.jpg ../data/brain/N/N051.jpg\n",
      "../micin/brain/N099.jpg ../data/brain/N/N099.jpg\n",
      "../micin/brain/PD034.jpg ../data/brain/PD/PD034.jpg\n",
      "../micin/brain/PS111.jpg ../data/brain/PS/PS111.jpg\n",
      "../micin/brain/N036.jpg ../data/brain/N/N036.jpg\n",
      "../micin/brain/MS061.jpg ../data/brain/MS/MS061.jpg\n",
      "../micin/brain/PS94.jpg ../data/brain/PS/PS94.jpg\n",
      "../micin/brain/PD142.jpg ../data/brain/PD/PD142.jpg\n",
      "../micin/brain/MS059.jpg ../data/brain/MS/MS059.jpg\n",
      "../micin/brain/PS044.jpg ../data/brain/PS/PS044.jpg\n",
      "../micin/brain/PS067.jpg ../data/brain/PS/PS067.jpg\n",
      "../micin/brain/N165.jpg ../data/brain/N/N165.jpg\n",
      "../micin/brain/PD128.jpg ../data/brain/PD/PD128.jpg\n",
      "../micin/brain/N001.jpg ../data/brain/N/N001.jpg\n",
      "../micin/brain/MS103.jpg ../data/brain/MS/MS103.jpg\n",
      "../micin/brain/MS146.jpg ../data/brain/MS/MS146.jpg\n",
      "../micin/brain/N126.jpg ../data/brain/N/N126.jpg\n",
      "../micin/brain/MS161.jpg ../data/brain/MS/MS161.jpg\n",
      "../micin/brain/PS117.jpg ../data/brain/PS/PS117.jpg\n",
      "../micin/brain/PD050.jpg ../data/brain/PD/PD050.jpg\n",
      "../micin/brain/N014.jpg ../data/brain/N/N014.jpg\n",
      "../micin/brain/MS147.jpg ../data/brain/MS/MS147.jpg\n",
      "../micin/brain/N009.jpg ../data/brain/N/N009.jpg\n",
      "../micin/brain/PD090.jpg ../data/brain/PD/PD090.jpg\n",
      "../micin/brain/N055.jpg ../data/brain/N/N055.jpg\n",
      "../micin/brain/N028.jpg ../data/brain/N/N028.jpg\n",
      "../micin/brain/N127.jpg ../data/brain/N/N127.jpg\n",
      "../micin/brain/PS040.jpg ../data/brain/PS/PS040.jpg\n",
      "../micin/brain/PD104.jpg ../data/brain/PD/PD104.jpg\n",
      "../micin/brain/N151.jpg ../data/brain/N/N151.jpg\n",
      "../micin/brain/PS027.jpg ../data/brain/PS/PS027.jpg\n",
      "../micin/brain/PD127.jpg ../data/brain/PD/PD127.jpg\n",
      "../micin/brain/N080.jpg ../data/brain/N/N080.jpg\n",
      "../micin/brain/PS84.jpg ../data/brain/PS/PS84.jpg\n",
      "../micin/brain/PS066.jpg ../data/brain/PS/PS066.jpg\n",
      "../micin/brain/PS030.jpg ../data/brain/PS/PS030.jpg\n",
      "../micin/brain/MS159.jpg ../data/brain/MS/MS159.jpg\n",
      "../micin/brain/PS068.jpg ../data/brain/PS/PS068.jpg\n",
      "../micin/brain/PD056.jpg ../data/brain/PD/PD056.jpg\n",
      "../micin/brain/MS139.jpg ../data/brain/MS/MS139.jpg\n",
      "../micin/brain/PD105.jpg ../data/brain/PD/PD105.jpg\n",
      "../micin/brain/N125.jpg ../data/brain/N/N125.jpg\n",
      "../micin/brain/PS042.jpg ../data/brain/PS/PS042.jpg\n",
      "../micin/brain/MS124.jpg ../data/brain/MS/MS124.jpg\n",
      "../micin/brain/PS114.jpg ../data/brain/PS/PS114.jpg\n",
      "../micin/brain/PS100.jpg ../data/brain/PS/PS100.jpg\n",
      "../micin/brain/N114.jpg ../data/brain/N/N114.jpg\n",
      "../micin/brain/N077.jpg ../data/brain/N/N077.jpg\n",
      "../micin/brain/PS74.jpg ../data/brain/PS/PS74.jpg\n",
      "../micin/brain/N064.jpg ../data/brain/N/N064.jpg\n",
      "../micin/brain/N038.jpg ../data/brain/N/N038.jpg\n",
      "../micin/brain/PS109.jpg ../data/brain/PS/PS109.jpg\n",
      "../micin/brain/N117.jpg ../data/brain/N/N117.jpg\n",
      "../micin/brain/N162.jpg ../data/brain/N/N162.jpg\n",
      "../micin/brain/PS81.jpg ../data/brain/PS/PS81.jpg\n",
      "../micin/brain/PS037.jpg ../data/brain/PS/PS037.jpg\n",
      "../micin/brain/N020.jpg ../data/brain/N/N020.jpg\n",
      "../micin/brain/PS024.jpg ../data/brain/PS/PS024.jpg\n",
      "../micin/brain/N067.jpg ../data/brain/N/N067.jpg\n",
      "../micin/brain/PS95.jpg ../data/brain/PS/PS95.jpg\n",
      "../micin/brain/MS050.jpg ../data/brain/MS/MS050.jpg\n",
      "../micin/brain/PS76.jpg ../data/brain/PS/PS76.jpg\n",
      "../micin/brain/N058.jpg ../data/brain/N/N058.jpg\n",
      "../micin/brain/PD039.jpg ../data/brain/PD/PD039.jpg\n",
      "../micin/brain/PS120.jpg ../data/brain/PS/PS120.jpg\n",
      "../micin/brain/PS035.jpg ../data/brain/PS/PS035.jpg\n",
      "../micin/brain/PS005.jpg ../data/brain/PS/PS005.jpg\n",
      "../micin/brain/MS149.jpg ../data/brain/MS/MS149.jpg\n",
      "../micin/brain/N121.jpg ../data/brain/N/N121.jpg\n",
      "../micin/brain/PD097.jpg ../data/brain/PD/PD097.jpg\n",
      "../micin/brain/N153.jpg ../data/brain/N/N153.jpg\n",
      "../micin/brain/MS104.jpg ../data/brain/MS/MS104.jpg\n",
      "../micin/brain/PS055.jpg ../data/brain/PS/PS055.jpg\n",
      "../micin/brain/N136.jpg ../data/brain/N/N136.jpg\n",
      "../micin/brain/PS107.jpg ../data/brain/PS/PS107.jpg\n",
      "../micin/brain/PD137.jpg ../data/brain/PD/PD137.jpg\n",
      "../micin/brain/PS019.jpg ../data/brain/PS/PS019.jpg\n",
      "../micin/brain/PS87.jpg ../data/brain/PS/PS87.jpg\n",
      "../micin/brain/PS098.jpg ../data/brain/PS/PS098.jpg\n",
      "../micin/brain/PD130.jpg ../data/brain/PD/PD130.jpg\n",
      "../micin/brain/PD116.jpg ../data/brain/PD/PD116.jpg\n",
      "../micin/brain/N095.jpg ../data/brain/N/N095.jpg\n",
      "../micin/brain/PD017.jpg ../data/brain/PD/PD017.jpg\n",
      "../micin/brain/N048.jpg ../data/brain/N/N048.jpg\n",
      "../micin/brain/N143.jpg ../data/brain/N/N143.jpg\n",
      "../micin/brain/PS86.jpg ../data/brain/PS/PS86.jpg\n",
      "../micin/brain/PS125.jpg ../data/brain/PS/PS125.jpg\n",
      "../micin/brain/N131.jpg ../data/brain/N/N131.jpg\n",
      "../micin/brain/PD044.jpg ../data/brain/PD/PD044.jpg\n",
      "../micin/brain/PS123.jpg ../data/brain/PS/PS123.jpg\n",
      "../micin/brain/MS96.jpg ../data/brain/MS/MS96.jpg\n",
      "../micin/brain/MS101.jpg ../data/brain/MS/MS101.jpg\n",
      "../micin/brain/PS063.jpg ../data/brain/PS/PS063.jpg\n",
      "../micin/brain/N073.jpg ../data/brain/N/N073.jpg\n",
      "../micin/brain/N105.jpg ../data/brain/N/N105.jpg\n",
      "../micin/brain/MS128.jpg ../data/brain/MS/MS128.jpg\n",
      "../micin/brain/MS166.jpg ../data/brain/MS/MS166.jpg\n",
      "../micin/brain/MS117.jpg ../data/brain/MS/MS117.jpg\n",
      "../micin/brain/PS060.jpg ../data/brain/PS/PS060.jpg\n",
      "../micin/brain/N031.jpg ../data/brain/N/N031.jpg\n",
      "../micin/brain/N118.jpg ../data/brain/N/N118.jpg\n",
      "../micin/brain/MS070.jpg ../data/brain/MS/MS070.jpg\n",
      "../micin/brain/PD022.jpg ../data/brain/PD/PD022.jpg\n",
      "../micin/brain/PS021.jpg ../data/brain/PS/PS021.jpg\n",
      "../micin/brain/PS121.jpg ../data/brain/PS/PS121.jpg\n",
      "../micin/brain/N102.jpg ../data/brain/N/N102.jpg\n",
      "../micin/brain/PS71.jpg ../data/brain/PS/PS71.jpg\n",
      "../micin/brain/PS122.jpg ../data/brain/PS/PS122.jpg\n",
      "../micin/brain/PD124.jpg ../data/brain/PD/PD124.jpg\n",
      "../micin/brain/PS72.jpg ../data/brain/PS/PS72.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "brain_dir = '../micin/brain/'\n",
    "data_dir = '../data/brain/'\n",
    "\n",
    "labels = ['N','MS','PD','PS']\n",
    "\n",
    "try:\n",
    "    os.mkdir(data_dir)\n",
    "except:\n",
    "    pass\n",
    "for label in labels:\n",
    "    try:\n",
    "        os.mkdir(data_dir+label)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "# 'PS116.jpg' -> ['PS', '116', '.jpg']\n",
    "import itertools\n",
    "strint_separator = lambda f:\\\n",
    "    [''.join(it) for _, it in itertools.groupby(f,str.isdigit)]\n",
    "\n",
    "\n",
    "flist = [ f for f in os.listdir(brain_dir) if '.jpg' in f ] # for removing .DS_Store\n",
    "for fname in flist:\n",
    "    label = strint_separator(fname)[0] # 'N','MS','PD' or'PS'\n",
    "    read_fname = brain_dir + fname\n",
    "    write_fname = data_dir + label + '/' + fname\n",
    "    open(write_fname, 'wb').write(open(read_fname,'rb').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brain_dir = '../micin/brain/'\n",
    "data_dir = '../data/brain'\n",
    "\n",
    "labels = ['N','MS','PDbrain_dir = '../micin/brain/'\n",
    "data_dir = '../data/brain'\n",
    "\n",
    "labels = ['N','MS','PD','PS']\n",
    "for label in labels:\n",
    "    try:\n",
    "        os.mkdir(data_dir+label)\n",
    "    except:\n",
    "        pass','PS']\n",
    "for label in labels:\n",
    "    try:\n",
    "        os.mkdir(data_dir+label)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'PS116.jpg' -> ['PS', '116', '.jpg']\n",
    "import itertools\n",
    "strint_separator = lambda f:\\\n",
    "    [''.join(it) for _, it in itertools.groupby(f,str.isdigit)]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flist = [ f for f in os.listdir(brain_dir) if '.jpg' in f ] # for removing .DS_Store\n",
    "for fname in flist: \n",
    "    label = strint_separator(fname)[0] # 'N','MS','PD' or'PS'\n",
    "    read_fname = brain_dir + fname\n",
    "    write_fname = data_dir + label + '/' + fname\n",
    "    open(write_fname, 'wb').write(open(read_fname,'rb').read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
